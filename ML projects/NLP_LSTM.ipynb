{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using LSTM\n",
    "\n",
    "We attempt to strengthen sentiment analysis models using LSTM layers.\n",
    "LSTM layers take into consideration the order in which words are written which makes them more effective in mimicing human behavior.\n",
    "We fit an LSTM model on the publically available movie reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our dataset\n",
    "Movies reviews are split into two categories (positive for 5/10 and above review and Negative for 4/10 and below reviews) \n",
    "\n",
    "We process our reviews using the keras built in Tokenizer function\n",
    "We then construct our train/test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Done!\n",
      "Ready to build our LSTM model\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import text_to_word_sequence, hashing_trick\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, LSTM, SpatialDropout1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "df=pd.read_csv('C:\\\\Users\\\\marwe\\\\Desktop\\\\movie_data.csv',encoding='utf-8')\n",
    "tk=Tokenizer()\n",
    "tk.fit_on_texts(df['review'])\n",
    "#print(len(tk.word_index))\n",
    "# summarize what was learned\n",
    "#print(len(tk.word_counts)) #dict each word and occurances in the whole dataset\n",
    "#print(tk.document_count) #number of docs used\n",
    "#print(tk.word_index['lack']) #list of words and their unique index\n",
    "#print(tk.word_docs['lack']) #words and number of appreances in docs\n",
    "#after fitting tokenizer we \n",
    "sequences = tk.texts_to_sequences(df['review'])\n",
    "data = pad_sequences(sequences, maxlen= 250) \n",
    "#print(data.shape) \n",
    "\n",
    "\n",
    "#constructing our training and testing set\n",
    "X_train=data[:25000]\n",
    "X_test=data[25000:]\n",
    "y_train=pd.get_dummies(df['sentiment'][:25000])\n",
    "y_test=pd.get_dummies(df['sentiment'][25000:])\n",
    "\n",
    "print('Preprocessing Done!')\n",
    "print('Ready to build our LSTM model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing and fitting LSTM for the movie reviews dataset\n",
    "\n",
    "We fit an LSTM to determine whether a movie review is positive/negative\n",
    "our LSTM includes: an embedding layer, LSTM layer and a final Dense layer for classification\n",
    "We also use Dropout layers to tackle overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 50)           6212650   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 250, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 6,232,952\n",
      "Trainable params: 6,232,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 120s 5ms/step - loss: 0.5574 - accuracy: 0.7079 - val_loss: 0.3809 - val_accuracy: 0.8380\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.3386 - accuracy: 0.8623 - val_loss: 0.3549 - val_accuracy: 0.8466\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 118s 5ms/step - loss: 0.2522 - accuracy: 0.9022 - val_loss: 0.3213 - val_accuracy: 0.8672\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 93s 4ms/step - loss: 0.1932 - accuracy: 0.9291 - val_loss: 0.3486 - val_accuracy: 0.8596\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 92s 4ms/step - loss: 0.1568 - accuracy: 0.9420 - val_loss: 0.3807 - val_accuracy: 0.8470\n",
      "25000/25000 [==============================] - 15s 598us/step\n",
      "Test score: 0.38071398198604584\n",
      "Test accuracy for our movie review classification problem: 0.8469600081443787\n"
     ]
    }
   ],
   "source": [
    "lstm_out = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tk.word_index)+1, 50, input_length=250))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size=200, verbose = 1,validation_data=(X_test,y_test))\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=200)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy for our movie review classification problem:', acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
