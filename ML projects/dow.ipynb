{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                               link  \\\n",
      "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
      "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
      "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
      "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
      "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
      "\n",
      "                                             content                 date  \\\n",
      "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
      "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
      "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
      "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
      "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
      "\n",
      "   retweets  favorites mentions hashtags  \n",
      "0       510        917      NaN      NaN  \n",
      "1        34        267      NaN      NaN  \n",
      "2        13         19      NaN      NaN  \n",
      "3        11         26      NaN      NaN  \n",
      "4      1375       1945      NaN      NaN  \n",
      "       id ticker                                              title category  \\\n",
      "0  221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
      "1  221516    NIO  NIO only consumer gainer  Workhorse Group amon...     news   \n",
      "2  221517    NIO  NIO leads consumer gainers  Beyond Meat and Ma...     news   \n",
      "3  221518    NIO                  NIO  NVAX among premarket gainers     news   \n",
      "4  221519    NIO                  PLUG  NIO among premarket gainers     news   \n",
      "\n",
      "                                             content release_date  \\\n",
      "0  What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
      "1  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
      "2  Gainers  NIO  NYSE NIO   14   Village Farms In...   2020-01-15   \n",
      "3  Cemtrex  NASDAQ CETX   85  after FY results \\n...   2020-01-15   \n",
      "4  aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   2020-01-06   \n",
      "\n",
      "          provider                                                url  \\\n",
      "0  The Motley Fool                             https://invst.ly/pigqi   \n",
      "1    Seeking Alpha                             https://invst.ly/pje9c   \n",
      "2    Seeking Alpha                             https://invst.ly/pifmv   \n",
      "3    Seeking Alpha                             https://invst.ly/picu8   \n",
      "4    Seeking Alpha  https://seekingalpha.com/news/3529772-plug-nio...   \n",
      "\n",
      "   article_id  \n",
      "0     2060327  \n",
      "1     2062196  \n",
      "2     2060249  \n",
      "3     2060039  \n",
      "4     2053096  \n",
      "   Unnamed: 0        date      timestamp  \\\n",
      "0           0  2012/10/01  1349064000000   \n",
      "1           1  2012/10/01  1349064000000   \n",
      "2           2  2012/10/01  1349064000000   \n",
      "3           3  2012/10/01  1349064000000   \n",
      "4           4  2012/10/01  1349064000000   \n",
      "\n",
      "                                               title  level2  level3  \n",
      "0  Catchings, January help Fever even series with...  sports    wnba  \n",
      "1  Kyle Busch rants on radio after his Toyota fal...  sports  nascar  \n",
      "2  Schwarzenegger says 'You can't run from your m...    life   books  \n",
      "3                                    Ryder Cup Day 3  sports    golf  \n",
      "4  Regular officials blow another big call agains...  gameon     NaN  \n",
      "         Date     Open    High      Low    Close  Adj Close    Volume\n",
      "0  2016-11-01  4802.75  4817.0  4718.75  4757.25    4757.25  307806.0\n",
      "1  2016-11-02  4754.50  4768.5  4708.25  4716.75    4716.75  300313.0\n",
      "2  2016-11-03  4700.00  4729.5  4668.25  4674.50    4674.50  280599.0\n",
      "3  2016-11-04  4671.25  4695.5  4651.25  4657.75    4657.75  264048.0\n",
      "4  2016-11-06      NaN     NaN      NaN      NaN        NaN       NaN\n",
      "         Date          Open          High           Low         Close  \\\n",
      "0  2016-11-01  18158.240234  18177.009766  17940.839844  18037.099609   \n",
      "1  2016-11-02  18017.720703  18044.150391  17931.890625  17959.640625   \n",
      "2  2016-11-03  17978.750000  18006.960938  17904.070313  17930.669922   \n",
      "3  2016-11-04  17928.349609  17986.759766  17883.560547  17888.279297   \n",
      "4  2016-11-07  17994.640625  18263.300781  17994.640625  18259.599609   \n",
      "\n",
      "      Adj Close     Volume  \n",
      "0  18037.099609  101280000  \n",
      "1  17959.640625   88610000  \n",
      "2  17930.669922   77860000  \n",
      "3  17888.279297   97760000  \n",
      "4  18259.599609   93450000  \n",
      "         Date     Open     High      Low    Close  Adj Close     Volume\n",
      "0  2016-11-01  2123.50  2129.50  2091.00  2103.75    2103.75  2257062.0\n",
      "1  2016-11-02  2102.25  2106.50  2087.25  2092.25    2092.25  2013595.0\n",
      "2  2016-11-03  2088.25  2098.75  2079.75  2083.50    2083.50  1795490.0\n",
      "3  2016-11-04  2084.00  2094.25  2078.75  2080.00    2080.00  2079129.0\n",
      "4  2016-11-06      NaN      NaN      NaN      NaN        NaN        NaN\n",
      "        Date                                              title\n",
      "0 2020-01-15  Why Shares of Chinese Electric Car Maker NIO A...\n",
      "1 2020-01-18  NIO only consumer gainer  Workhorse Group amon...\n",
      "4 2020-01-06  PLUG  NIO among premarket gainers. NIO up 6  o...\n",
      "5 2019-12-31  NIO leads consumer gainers  Origin Agritech on...\n",
      "6 2020-01-07  Beyond Meat tops consumer gainers  NIO and Eas...\n",
      "         date                                              title  level2\n",
      "0  2012/10/01  Catchings, January help Fever even series with...  sports\n",
      "1  2012/10/01  Kyle Busch rants on radio after his Toyota fal...  sports\n",
      "2  2012/10/01  Schwarzenegger says 'You can't run from your m...    life\n",
      "3  2012/10/01                                    Ryder Cup Day 3  sports\n",
      "4  2012/10/01  Regular officials blow another big call agains...  gameon\n",
      "             Date                                              title\n",
      "566274 2016-11-08  FTC sends $3.7M to victims of pyramid scheme. ...\n",
      "566747 2016-11-09  Trump website glitch fixed, but not before Int...\n",
      "567390 2016-11-10  Every bit of positivity counts. Here's how to ...\n",
      "567966 2016-11-11  Student gives 'deportation' notices to other k...\n",
      "568476 2016-11-12  Clintons are a 'talented family,' Trump tells ...\n",
      "            Date                                            content\n",
      "30887 2016-11-08  Today we are going to win the great state of M...\n",
      "30897 2016-11-09  Such a beautiful and important evening! The fo...\n",
      "30898 2016-11-10  Happy 241st birthday to the U.S. Marine Corps!...\n",
      "30901 2016-11-11  Love the fact that the small groups of protest...\n",
      "30904 2016-11-12  This will prove to be a great time in the live...\n",
      "         Date  Up_sp\n",
      "6  2016-11-07      1\n",
      "7  2016-11-08      1\n",
      "8  2016-11-09      1\n",
      "10 2016-11-13      0\n",
      "11 2016-11-14      1\n",
      "         Date  Close_sp\n",
      "6  2016-11-07   2135.50\n",
      "7  2016-11-08   2160.25\n",
      "8  2016-11-09   2167.25\n",
      "10 2016-11-13   2160.50\n",
      "11 2016-11-14   2179.25\n",
      "Base model for each stock\n",
      "Dow:  0.5590851334180432\n",
      "sp:  0.5933926302414231\n",
      "nas:  0.5921219822109276\n",
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "path=\"C:\\\\Users\\\\marwe\\\\Desktop\\\\Trump_tweet_news_stock\"\n",
    "#read trump tweets\n",
    "df_tweets=pd.read_csv(path+\"\\\\realdonaldtrump.csv\")\n",
    "print(df_tweets.head())\n",
    "\n",
    "\n",
    "#stock news\n",
    "df_stock_news=pd.read_csv(\"C:\\\\Users\\\\marwe\\\\Desktop\\\\LaTeX JOTA\\\\us_equities_news_dataset.csv\")\n",
    "print(df_stock_news.head())\n",
    "\n",
    "#read the news dataset from usa today\n",
    "df_news=pd.read_csv(path+\"\\\\USA Today.csv\")\n",
    "print(df_news.head())\n",
    "\n",
    "#read nasdaq, s&p500 and dow\n",
    "\n",
    "df_nasdaq=pd.read_csv(path+\"\\\\NASDAQ_price.csv\")\n",
    "print(df_nasdaq.head())\n",
    "\n",
    "\n",
    "\n",
    "df_Dow=pd.read_csv(path+\"\\\\DowJones_price.csv\")\n",
    "print(df_Dow.head())\n",
    "\n",
    "df_sp=pd.read_csv(\"C:\\\\Users\\\\marwe\\\\Desktop\\\\Trump_tweet_news_stock\\\\SP_price.csv\")\n",
    "print(df_sp.head())\n",
    "\n",
    "\n",
    "\n",
    "#preparing the news dataset\n",
    "'''\n",
    "we will first rearrange the news then add columns for the stock market\n",
    "dates are between election and 2020-04-03 (one day after the news stop)\n",
    "\n",
    "'''\n",
    "\n",
    "df_stock_news=df_stock_news.rename(columns={\"release_date\":\"Date\"})\n",
    "df_stock_news['Date'] = pd.to_datetime(df_stock_news['Date']) \n",
    "df_stock_news['Date'] = pd.to_datetime(df_stock_news['Date']) \n",
    "mask = (df_stock_news['Date'] >= '2016-11-8' )\n",
    "df_stock_news=df_stock_news.loc[mask]\n",
    "col=['Date','title']\n",
    "df_stock_news=df_stock_news[col]\n",
    "\n",
    "#df_stock_news.content = np.where(df_stock_news.content.isnull(),str(df_stock_news.Date),str(df_stock_news.content))\n",
    "#toronto_df['Neighbourhood'] = toronto_df.groupby(['Postcode','Borough'])['Neighbourhood'].agg(lambda x: ','.join(x))\n",
    "\n",
    "df_stock_news['title']=df_stock_news['title'].fillna(\" \")\n",
    "df_stock_news['title'] = df_stock_news[['Date','title']].groupby(['Date'])['title'].transform(lambda x: '. '.join(x))\n",
    "df_stock_news=df_stock_news[['Date','title']].drop_duplicates()\n",
    "print(df_stock_news.head())\n",
    "\n",
    "#col_selection=[\"news\",\"money\",\"onpolitics\",\"theoval\"]\n",
    "col=['date','title','level2']\n",
    "df_news=df_news[col]\n",
    "print(df_news.head())\n",
    "#df_news=df_news.loc[df_news['level2'] != 'sports']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'entertainment']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'travel']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'gameon']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'music']\n",
    "df_news=df_news.loc[(df_news['level2'] == \"news\")|(df_news['level2'] == \"money\")|(df_news['level2'] == \"onpolitics\")|(df_news['level2'] == \"theoval\")]\n",
    "#pick between the dates needed\n",
    "df_news=df_news.rename(columns={\"date\":\"Date\"})\n",
    "df_news['Date'] = pd.to_datetime(df_news['Date']) \n",
    "mask = (df_news['Date'] >= '2016-11-8' )\n",
    "df_news=df_news.loc[mask]\n",
    "col=['Date','title']\n",
    "df_news=df_news[col]\n",
    "df_news['title'] = df_news[['Date','title']].groupby(['Date'])['title'].transform(lambda x: '. '.join(x))\n",
    "df_news=df_news[['Date','title']].drop_duplicates()\n",
    "print(df_news.head())\n",
    "\n",
    "def sub_one(x):\n",
    "\treturn x -timedelta(days=1)\n",
    "\n",
    "#make sure dow nasdaq and s&p are recorded between the 2 dates\n",
    "#dow\n",
    "df_Dow['Date'] = pd.to_datetime(df_Dow['Date']) \n",
    "mask = (df_Dow['Date'] >= '2016-11-8') &  (df_Dow['Date'] <= '2020-4-3')\n",
    "df_Dow=df_Dow.loc[mask]\n",
    "colo=['Date','Open','Close','Adj Close']\n",
    "df_Dow=df_Dow[colo]\n",
    "df_Dow['Adj Close']=np.where(df_Dow['Close']>=df_Dow['Open'],1,0)\n",
    "df_Dow=df_Dow.rename(columns={\"Adj Close\":\"Up_Dow\"})\n",
    "df_Dow=df_Dow.rename(columns={\"Close\":\"Close_Dow\"})\n",
    "df_Dow['Date']=df_Dow['Date'].apply(sub_one)\n",
    "\n",
    "#col_Dow=['Date','Up_Dow']\n",
    "#df_Dow=df_Dow.loc[col_Dow]\n",
    "\n",
    "\n",
    "#nasdaq\n",
    "df_nasdaq['Date'] = pd.to_datetime(df_nasdaq['Date']) \n",
    "mask = (df_nasdaq['Date'] >= '2016-11-8') &  (df_nasdaq['Date'] <= '2020-4-3')\n",
    "df_nasdaq=df_nasdaq.loc[mask]\n",
    "df_nasdaq=df_nasdaq.dropna()\n",
    "df_nasdaq=df_nasdaq[colo]\n",
    "df_nasdaq['Adj Close']=np.where(df_nasdaq['Close']>=df_nasdaq['Open'],1,0)\n",
    "df_nasdaq=df_nasdaq.rename(columns={\"Adj Close\":\"Up_nas\"})\n",
    "df_nasdaq=df_nasdaq.rename(columns={\"Close\":\"Close_nas\"})\n",
    "df_nasdaq['Date']=df_nasdaq['Date'].apply(sub_one)\n",
    "#col_nasdaq=['Date','Close_nas','Up_nas']\n",
    "#df_nasdaq=df_nasdaq.loc[col_nasdaq]\n",
    "\n",
    "#SP\n",
    "df_sp['Date'] = pd.to_datetime(df_sp['Date']) \n",
    "mask = (df_sp['Date'] >= '2016-11-8') &  (df_sp['Date'] <= '2020-4-3')\n",
    "df_sp=df_sp.loc[mask]\n",
    "df_sp=df_sp.dropna()\n",
    "df_sp=df_sp[colo]\n",
    "df_sp['Adj Close']=np.where(df_sp['Close']>=df_sp['Open'],1,0)\n",
    "df_sp=df_sp.rename(columns={\"Adj Close\":\"Up_sp\"})\n",
    "df_sp=df_sp.rename(columns={\"Close\":\"Close_sp\"})\n",
    "df_sp['Date']=df_sp['Date'].apply(sub_one)\n",
    "\n",
    "#col_sp=['Date','Close_sp','Up_sp']\n",
    "#df_sp=df_sp.loc[col_sp]\n",
    "\n",
    "#trying merge\n",
    "margo=pd.merge(df_news, df_Dow, how='outer', on='Date')\n",
    "margo=pd.merge(margo,df_nasdaq, how='outer', on='Date')\n",
    "df_news_pred=pd.merge(margo,df_sp, how='outer', on='Date')\n",
    "df_news_pred=pd.merge(df_news_pred,df_stock_news, how='outer', on='Date')\n",
    "\n",
    "\n",
    "\n",
    "col_margo=['Date','title_x','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp','title_y']\n",
    "df_news_pred=df_news_pred[col_margo]\n",
    "df_news_pred=df_news_pred.dropna()\n",
    "df_news_pred['title_x'] = df_news_pred[['Date','title_x','title_y']].groupby(['Date'])['title_x'].transform(lambda x: '. '.join(x))\n",
    "col_margo=['Date','title_x','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp']\n",
    "df_news_pred=df_news_pred[col_margo]\n",
    "\n",
    "'''\n",
    "we created df_news_pred, a dataset that has daily news headlines as input and next day stock market prediction\n",
    "we will use this data to predict the stock market using possibly RNN \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Now we do the same for trump tweets\n",
    "'''\n",
    "#initial preprocessing and selecting the dates\n",
    "df_tweets=df_tweets.rename(columns={\"date\":\"Date\"})\n",
    "df_tweets['Date'] = pd.to_datetime(df_tweets['Date']) \n",
    "df_tweets = df_tweets.assign(Date = lambda x: pd.to_datetime(x['Date'].dt.strftime('%Y-%m-%d')))\n",
    "mask = (df_tweets['Date'] >= '2016-11-8') &  (df_tweets['Date'] <= '2020-4-3')\n",
    "df_tweets=df_tweets.loc[mask]\n",
    "\n",
    "\n",
    "#merge tweets according to date\n",
    "df_tweets['content'] = df_tweets[['Date','content']].groupby(['Date'])['content'].transform(lambda x: '. '.join(x))\n",
    "df_tweets=df_tweets[['Date','content']].drop_duplicates()\n",
    "print(df_tweets.head())\n",
    "\n",
    "#construct the input/output table with next day prediction\n",
    "margo=pd.merge(df_tweets, df_Dow, how='outer', on='Date')\n",
    "margo=pd.merge(margo,df_nasdaq, how='outer', on='Date')\n",
    "df_tweet_pred=pd.merge(margo,df_sp, how='outer', on='Date')\n",
    "\n",
    "col_margo=['Date','content','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp']\n",
    "df_tweet_pred=df_tweet_pred[col_margo]\n",
    "df_tweet_pred=df_tweet_pred.dropna()\n",
    "\n",
    "\n",
    "'''\n",
    "we created df_tweet_pred, a dataset that has daily trump tweets as input and next day stock market prediction\n",
    "we will use this data to predict the stock market using possibly RNN \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "now we prepare the time series data, we want the data to look like the following\n",
    "5 past observations of stock market info as input and then todays market info as output\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# up an down table for sp\n",
    "\n",
    "df_sp_his=pd.DataFrame()\n",
    "df_sp_his['Date']=df_sp['Date']\n",
    "df_sp_his['Up_sp']=df_sp['Up_sp']\n",
    "print(df_sp_his.head())\n",
    "df_sp_his['t-1sp']=df_sp['Up_sp'].shift(1)\n",
    "df_sp_his['t-2sp']=df_sp['Up_sp'].shift(2)\n",
    "df_sp_his['t-3sp']=df_sp['Up_sp'].shift(3)\n",
    "df_sp_his['t-4sp']=df_sp['Up_sp'].shift(4)\n",
    "df_sp_his['t-5sp']=df_sp['Up_sp'].shift(5)\n",
    "df_sp_his['t-6sp']=df_sp['Up_sp'].shift(6)\n",
    "\n",
    "# up an down table for Dow\n",
    "df_dow_his=pd.DataFrame()\n",
    "df_dow_his['Date']=df_Dow['Date']\n",
    "df_dow_his['Up_Dow']=df_Dow['Up_Dow']\n",
    "df_dow_his['t-1Dow']=df_Dow['Up_Dow'].shift(1)\n",
    "df_dow_his['t-2Dow']=df_Dow['Up_Dow'].shift(2)\n",
    "df_dow_his['t-3Dow']=df_Dow['Up_Dow'].shift(3)\n",
    "df_dow_his['t-4Dow']=df_Dow['Up_Dow'].shift(4)\n",
    "df_dow_his['t-5Dow']=df_Dow['Up_Dow'].shift(5)\n",
    "df_dow_his['t-6Dow']=df_Dow['Up_Dow'].shift(6)\n",
    "\n",
    "# up an down table for nasdaq\n",
    "df_nas_his=pd.DataFrame()\n",
    "df_nas_his['Date']=df_nasdaq['Date']\n",
    "df_nas_his['Up_nas']=df_nasdaq['Up_nas']\n",
    "df_nas_his['t-1nas']=df_nasdaq['Up_nas'].shift(1)\n",
    "df_nas_his['t-2nas']=df_nasdaq['Up_nas'].shift(2)\n",
    "df_nas_his['t-3nas']=df_nasdaq['Up_nas'].shift(3)\n",
    "df_nas_his['t-4nas']=df_nasdaq['Up_nas'].shift(4)\n",
    "df_nas_his['t-5nas']=df_nasdaq['Up_nas'].shift(5)\n",
    "df_nas_his['t-6nas']=df_nasdaq['Up_nas'].shift(6)\n",
    "\n",
    "\n",
    "#same for the price\n",
    "\n",
    "# price table for sp\n",
    "df_spp_his=pd.DataFrame()\n",
    "df_spp_his['Date']=df_sp['Date']\n",
    "df_spp_his['Close_sp']=df_sp['Close_sp']\n",
    "print(df_spp_his.head())\n",
    "df_spp_his['t-1spp']=df_sp['Close_sp'].shift(1)\n",
    "df_spp_his['t-2spp']=df_sp['Close_sp'].shift(2)\n",
    "df_spp_his['t-3spp']=df_sp['Close_sp'].shift(3)\n",
    "df_spp_his['t-4spp']=df_sp['Close_sp'].shift(4)\n",
    "df_spp_his['t-5spp']=df_sp['Close_sp'].shift(5)\n",
    "df_spp_his['t-6spp']=df_sp['Close_sp'].shift(6)\n",
    "\n",
    "# price for Dow\n",
    "df_dowp_his=pd.DataFrame()\n",
    "df_dowp_his['Date']=df_Dow['Date']\n",
    "df_dowp_his['Close_Dow']=df_Dow['Close_Dow']\n",
    "df_dowp_his['t-1Dowp']=df_Dow['Close_Dow'].shift(1)\n",
    "df_dowp_his['t-2Dowp']=df_Dow['Close_Dow'].shift(2)\n",
    "df_dowp_his['t-3Dowp']=df_Dow['Close_Dow'].shift(3)\n",
    "df_dowp_his['t-4Dowp']=df_Dow['Close_Dow'].shift(4)\n",
    "df_dowp_his['t-5Dowp']=df_Dow['Close_Dow'].shift(5)\n",
    "df_dowp_his['t-6Dowp']=df_Dow['Close_Dow'].shift(6)\n",
    "\n",
    "# price for nasdaq\n",
    "df_nasp_his=pd.DataFrame()\n",
    "df_nasp_his['Date']=df_nasdaq['Date']\n",
    "df_nasp_his['Close_nas']=df_nasdaq['Close_nas']\n",
    "df_nasp_his['t-1nasp']=df_nasdaq['Close_nas'].shift(1)\n",
    "df_nasp_his['t-2nasp']=df_nasdaq['Close_nas'].shift(2)\n",
    "df_nasp_his['t-3nasp']=df_nasdaq['Close_nas'].shift(3)\n",
    "df_nasp_his['t-4nasp']=df_nasdaq['Close_nas'].shift(4)\n",
    "df_nasp_his['t-5nasp']=df_nasdaq['Close_nas'].shift(5)\n",
    "df_nasp_his['t-6nasp']=df_nasdaq['Close_nas'].shift(6)\n",
    "\n",
    "'''\n",
    "lets recap the input we got so far:\n",
    "df_news_pred: has daily news headlines and market predictions for sp/dow/nas\n",
    "df_tweet_pred: has daily trump tweets and then market predictions\n",
    "\n",
    "lastly we have time series data for nas/sp/dow for ups downs and prices (6 datasets in total)\n",
    "\n",
    "a total of 8 useful datasets, need to figure out a way to clean it further and construct a model\n",
    "'''\n",
    "\n",
    "'''\n",
    "lets try to merge some stuff\n",
    "'''\n",
    "\n",
    "merge_twt_news=pd.merge(df_tweet_pred,df_news_pred, how='outer', on=['Date','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp'])\n",
    "#merge_twt_news=pd.merge(merge_twt_news,df_sp_his, how='outer', on=['Date','Up_sp'])\n",
    "#merge_twt_news=pd.merge(merge_twt_news,df_nas_his, how='outer', on=['Date','Up_nas'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_sp_his, how='outer', on=['Date','Up_sp'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_dow_his, how='outer', on=['Date','Up_Dow'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_nas_his, how='outer', on=['Date','Up_nas'])\n",
    "\n",
    "merge_twt_news=merge_twt_news.dropna()\n",
    "\n",
    "\n",
    "'''\n",
    "lets preprocess the text columns first, we will preprocess tweets and news seperately\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "twt_words=20000\n",
    "maxlen_twt=500\n",
    "\n",
    "tok_tweet = Tokenizer(num_words=twt_words)\n",
    "tok_tweet.fit_on_texts(merge_twt_news['content'])\n",
    "merge_twt_news['content']=tok_tweet.texts_to_sequences(merge_twt_news['content'])\n",
    "x_tweet = preprocessing.sequence.pad_sequences(merge_twt_news['content'], maxlen=500)\n",
    "\n",
    "\n",
    "#do the same fro the news\n",
    "\n",
    "news_words=30000\n",
    "maxlen_news=1500\n",
    "\n",
    "tok_news = Tokenizer(num_words=news_words)\n",
    "tok_news.fit_on_texts(merge_twt_news['title_x'])\n",
    "merge_twt_news['title_x']=tok_news.texts_to_sequences(merge_twt_news['title_x'])\n",
    "x_news = preprocessing.sequence.pad_sequences(merge_twt_news['title_x'], maxlen=maxlen_news)\n",
    "merge_twt_news=merge_twt_news.drop(['content', 'title_x'], axis=1)\n",
    "#col_dow=['t-6Dow','t-5Dow','t-4Dow','t-3Dow','t-2Dow','t-1Dow','t-6sp','t-5sp','t-4sp','t-3sp','t-2sp','t-1sp','t-6nas','t-5nas','t-4nas','t-3nas','t-2nas','t-1nas']\n",
    "\n",
    "\n",
    "col_sp=['t-6sp','t-5sp','t-4sp','t-3sp','t-2sp','t-1sp']\n",
    "col_nas=['t-6nas','t-5nas','t-4nas','t-3nas','t-2nas','t-1nas']\n",
    "col_dow=['t-6Dow','t-5Dow','t-4Dow','t-3Dow','t-2Dow','t-1Dow']\n",
    "#y=merge_twt_news['Up_Dow']\n",
    "\n",
    "\"\"\"\n",
    "Constructing our X dataset for each stock\n",
    "\n",
    "\"\"\"\n",
    "#Dow\n",
    "X_dowp=merge_twt_news[col_dow]\n",
    "X_dowp=np.hstack((x_tweet,x_news,X_dowp))\n",
    "\n",
    "#nas\n",
    "X_nasp=merge_twt_news[col_nas]\n",
    "X_nasp=np.hstack((x_tweet,x_news,X_nasp))\n",
    "\n",
    "#sp\n",
    "X_spp=merge_twt_news[col_sp]\n",
    "X_spp=np.hstack((x_tweet,x_news,X_spp))\n",
    "\n",
    "#X_dowp_train,X_dowp_test,y_dowp_train,y_dowp_test= train_test_split(X_dowp,merge_twt_news[['Up_Dow','Up_sp','Up_nas']],test_size=0.25,random_state=0) #['Up_Dow'] for class\n",
    "\n",
    "X_dowp_train,X_dowp_test,y_dowp_train,y_dowp_test= train_test_split(X_dowp,merge_twt_news[['Up_Dow']],test_size=0.01,random_state=42)\n",
    "X_nasp_train,X_nasp_test,y_nasp_train,y_nasp_test= train_test_split(X_nasp,merge_twt_news[['Up_nas']],test_size=0.01,random_state=42)\n",
    "X_spp_train,X_spp_test,y_spp_train,y_spp_test= train_test_split(X_spp,merge_twt_news[['Up_sp']],test_size=0.01,random_state=42)\n",
    "#X_dowp_test,X_dowp_val,y_dowp_test,y_dowp_val= train_test_split(X_dowp_test,y_dowp_test,test_size=0.5,random_state=0,stratify=y_dowp_test)\n",
    "\n",
    "\n",
    "\n",
    "word_index_twitter = tok_tweet.word_index\n",
    "word_index_news = tok_news.word_index\n",
    "\n",
    "\n",
    "\n",
    "#skf=StratifiedKFold(n_splits=10,random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "LETS START WORKING ON THE MODEL\n",
    "'''\n",
    "\n",
    "'''\n",
    "any model that we work on needs to beat the base model: we assume given the current economy\n",
    "that the stock market will be rising (dow in this case) so prediction will always be 1\n",
    "'''\n",
    "y_base=np.ones(len( X_dowp_train),)\n",
    "print(\"Base model for each stock\")\n",
    "print(\"Dow: \",np.mean(y_base==y_dowp_train['Up_Dow']))\n",
    "print(\"sp: \",np.mean(y_base==y_spp_train['Up_sp']))\n",
    "print(\"nas: \",np.mean(y_base==y_nasp_train['Up_nas'])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start updating here please\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#2nd model no twitter but rnn\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy without twitter but rnn')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "#plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.title('Training and validation loss no twitt but rnn')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#3rd model rnn and twitter\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history3.history['accuracy']\n",
    "val_acc = history3.history['val_accuracy']\n",
    "loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy with twitter and rnn')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "#plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.title('Training and validation loss with twitt and rnn')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "now we need to start the regularization process as well as adding things to help\n",
    "solve the scarcity of data like pretrained embeddings \n",
    "also be careful we have a very big overfitting problem\n",
    "'''\n",
    "\n",
    "'''\n",
    "first we will try to handle lack of data by introducting a pre trained embedding vectors\n",
    "we will use the twitter GLOVE pretrained word vector\n",
    "lets prepare everything\n",
    "'''\n",
    "\n",
    "#unzip the twitter glove and setup the index\n",
    "import os\n",
    "\n",
    "glove_dir = 'C:\\\\Users\\\\marwe\\\\Desktop\\\\Glove'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.twitter.27B.100d.txt'),encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "#setup the vocab vector for the twitter dataset\n",
    "embedding_dim = 100\n",
    "embedding_matrix_tweet = np.zeros((twt_words, embedding_dim))\n",
    "for word, i in word_index_twitter.items():\n",
    "    if i < twt_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_tweet[i] = embedding_vector\n",
    "\n",
    "\n",
    "#setup the vocab vector for the news dataset\n",
    "embedding_dim = 100\n",
    "embedding_matrix_news = np.zeros((news_words, embedding_dim))\n",
    "for word, i in word_index_news.items():\n",
    "    if i < news_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_news[i] = embedding_vector\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all models constructed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "construct all models\n",
    "\"\"\"\n",
    "\n",
    "def model_0():\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words+1,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y=layers.Flatten()(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(3,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),name='f',return_sequences=True)(input_hist)\n",
    "    z=layers.Flatten()(z)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined1 = layers.concatenate([y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), activation=\"relu\",name='h')(combined1)\n",
    "    \n",
    "    #dow = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    #sp = layers.Dense(1, activation=\"sigmoid\",name='j')(m)\n",
    "    nas= layers.Dense(1, activation=\"sigmoid\",name='k')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    #model = Model(inputs=[ y.input,z.input], outputs=[dow,sp,nas])\n",
    "    model = Model(inputs=[ y.input,z.input], outputs=nas)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #model.compile(loss='mse', optimizer='rmsprop', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "lets introduce RNN for the news to see if we get better results \n",
    "\n",
    "'''\n",
    "def model_1():\n",
    "    #input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    \n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,return_sequences=False,name='e')(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(3,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),name='f')(input_hist)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), activation=\"relu\",name='h')(combined)\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "lets intorduce the twitter feed\n",
    "'''\n",
    "\n",
    "# define 3 sets of inputs\n",
    "def model_2():\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=64,input_length=500,name='a')(input_tweet)\n",
    "    x = layers.LSTM(32,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), return_sequences=False,name='b')(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),return_sequences=False,name='e')(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(3,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),name='f')(input_hist)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), activation=\"relu\",name='h')(combined)\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "after loading the glove embedding vectorizer, lets try our previous model and see what we obtain\n",
    "'''\n",
    "# define 3 sets of inputs\n",
    "def model_3():\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=embedding_dim,weights=[embedding_matrix_tweet],trainable=False,input_length=500,name='a')(input_tweet)\n",
    "    x = layers.LSTM(32,return_sequences=False,name='b')(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=embedding_dim,weights=[embedding_matrix_news],trainable=False,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,return_sequences=False,name='e')(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(6,name='f')(input_hist) #used to be 3\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(16, activation=\"relu\",name='h')(combined)#used to be 8\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "lets try some regulirazation techniques\n",
    "'''\n",
    "\n",
    "def model_4():\n",
    "# define 3 sets of inputs\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=embedding_dim,weights=[embedding_matrix_tweet],trainable=False,input_length=500,name='a')(input_tweet)\n",
    "    #x = layers.Bidirectional(layers.LSTM(32,return_sequences=False,recurrent_dropout=0.33,dropout=0.33,name='b'))(x)\n",
    "    x=(layers.LSTM(33,return_sequences=False,recurrent_dropout=0.33,dropout=0.33,name='b'))(x)\n",
    "    #x=(layers.LSTM(40,return_sequences=False,recurrent_dropout=0.3,dropout=0.3,name='t'))(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=embedding_dim,weights=[embedding_matrix_news],trainable=False,input_length=1500,name='c')(input_news)\n",
    "    #y= layers.Bidirectional(layers.LSTM(32,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='e'))(y)\n",
    "    y=(layers.LSTM(33,return_sequences=False,recurrent_dropout=0.33,dropout=0.33,name='e'))(y)\n",
    "    #y=(layers.LSTM(40,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='ae'))(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    #z = layers.Bidirectional(layers.LSTM(6,name='f',recurrent_dropout=0.1,dropout=0.1))(input_hist)\n",
    "    z=(layers.LSTM(5,name='f'))(input_hist)#used to be 3\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8, activation=\"tanh\",name='h')(combined)\n",
    "    m=layers.Dropout(0.1)(m)#used to be 8\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"all models constructed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dow training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 661 samples, validate on 126 samples\n",
      "Epoch 1/25\n",
      "661/661 [==============================] - 3s 5ms/step - loss: 1.6397 - accuracy: 0.5492 - val_loss: 1.1034 - val_accuracy: 0.5238\n",
      "Epoch 2/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.9694 - accuracy: 0.5310 - val_loss: 0.8927 - val_accuracy: 0.5238\n",
      "Epoch 3/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8721 - accuracy: 0.5582 - val_loss: 0.8694 - val_accuracy: 0.5238\n",
      "Epoch 4/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8604 - accuracy: 0.5688 - val_loss: 0.8538 - val_accuracy: 0.5238\n",
      "Epoch 5/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8424 - accuracy: 0.5658 - val_loss: 0.8606 - val_accuracy: 0.5238\n",
      "Epoch 6/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8435 - accuracy: 0.5658 - val_loss: 0.8553 - val_accuracy: 0.5238\n",
      "Epoch 7/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8437 - accuracy: 0.5658 - val_loss: 0.8811 - val_accuracy: 0.5238\n",
      "Epoch 8/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8450 - accuracy: 0.5658 - val_loss: 0.8882 - val_accuracy: 0.5238\n",
      "Epoch 9/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.8282 - accuracy: 0.5658 - val_loss: 0.9287 - val_accuracy: 0.5238\n",
      "Epoch 10/25\n",
      "661/661 [==============================] - 2s 2ms/step - loss: 0.7822 - accuracy: 0.5658 - val_loss: 0.9531 - val_accuracy: 0.5238\n",
      "Epoch 11/25\n",
      "661/661 [==============================] - 2s 2ms/step - loss: 0.7200 - accuracy: 0.5658 - val_loss: 0.9585 - val_accuracy: 0.5238\n",
      "Epoch 12/25\n",
      "661/661 [==============================] - 2s 2ms/step - loss: 0.6731 - accuracy: 0.5658 - val_loss: 0.9609 - val_accuracy: 0.5238\n",
      "Epoch 13/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.6513 - accuracy: 0.5658 - val_loss: 0.9577 - val_accuracy: 0.5238\n",
      "Epoch 14/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.6228 - accuracy: 0.8865 - val_loss: 0.9364 - val_accuracy: 0.5238\n",
      "Epoch 15/25\n",
      "661/661 [==============================] - 2s 2ms/step - loss: 0.5971 - accuracy: 0.9924 - val_loss: 0.9389 - val_accuracy: 0.5238\n",
      "Epoch 16/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.9970 - val_loss: 0.9345 - val_accuracy: 0.5238\n",
      "Epoch 17/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5748 - accuracy: 0.9985 - val_loss: 0.9485 - val_accuracy: 0.5238\n",
      "Epoch 18/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.9970 - val_loss: 0.9287 - val_accuracy: 0.5238\n",
      "Epoch 19/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.5238\n",
      "Epoch 20/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.5238\n",
      "Epoch 21/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.5238\n",
      "Epoch 22/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5146 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.5238\n",
      "Epoch 23/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.5238\n",
      "Epoch 24/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.5238\n",
      "Epoch 25/25\n",
      "661/661 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 661 samples, validate on 126 samples\n",
      "Epoch 1/25\n",
      "661/661 [==============================] - 30s 45ms/step - loss: 0.7760 - accuracy: 0.4690 - val_loss: 0.7679 - val_accuracy: 0.4921\n",
      "Epoch 2/25\n",
      "661/661 [==============================] - 30s 46ms/step - loss: 0.7590 - accuracy: 0.6717 - val_loss: 0.7599 - val_accuracy: 0.5000\n",
      "Epoch 3/25\n",
      "661/661 [==============================] - 30s 46ms/step - loss: 0.7257 - accuracy: 0.7655 - val_loss: 0.7652 - val_accuracy: 0.4683\n",
      "Epoch 4/25\n",
      "661/661 [==============================] - 31s 46ms/step - loss: 0.5341 - accuracy: 0.9365 - val_loss: 0.8533 - val_accuracy: 0.4762\n",
      "Epoch 5/25\n",
      "661/661 [==============================] - 30s 46ms/step - loss: 0.3570 - accuracy: 0.9924 - val_loss: 1.0227 - val_accuracy: 0.4921\n",
      "Epoch 6/25\n",
      "661/661 [==============================] - 31s 47ms/step - loss: 0.3188 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.4841\n",
      "Epoch 7/25\n",
      "661/661 [==============================] - 31s 47ms/step - loss: 0.2973 - accuracy: 1.0000 - val_loss: 1.0040 - val_accuracy: 0.5000\n",
      "Epoch 8/25\n",
      "661/661 [==============================] - 31s 47ms/step - loss: 0.2825 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.4603\n",
      "Epoch 9/25\n",
      "661/661 [==============================] - 33s 50ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.4762\n",
      "Epoch 10/25\n",
      "661/661 [==============================] - 36s 55ms/step - loss: 0.2588 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.5000\n",
      "Epoch 11/25\n",
      "661/661 [==============================] - 36s 55ms/step - loss: 0.2488 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.4841\n",
      "Epoch 12/25\n",
      "661/661 [==============================] - 36s 54ms/step - loss: 0.2395 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.5476\n",
      "Epoch 13/25\n",
      "661/661 [==============================] - 32s 48ms/step - loss: 0.2309 - accuracy: 1.0000 - val_loss: 1.0519 - val_accuracy: 0.5317\n",
      "Epoch 14/25\n",
      "661/661 [==============================] - 31s 46ms/step - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.4603\n",
      "Epoch 15/25\n",
      "661/661 [==============================] - 31s 48ms/step - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.4683\n",
      "Epoch 16/25\n",
      "661/661 [==============================] - 32s 48ms/step - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.1110 - val_accuracy: 0.4841\n",
      "Epoch 17/25\n",
      "661/661 [==============================] - 32s 48ms/step - loss: 0.2023 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.5079\n",
      "Epoch 18/25\n",
      "661/661 [==============================] - 33s 49ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 1.1096 - val_accuracy: 0.5397\n",
      "Epoch 19/25\n",
      "661/661 [==============================] - 36s 54ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 1.1103 - val_accuracy: 0.5476\n",
      "Epoch 20/25\n",
      "661/661 [==============================] - 37s 56ms/step - loss: 0.1855 - accuracy: 1.0000 - val_loss: 1.1478 - val_accuracy: 0.5238\n",
      "Epoch 21/25\n",
      "661/661 [==============================] - 35s 53ms/step - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.1839 - val_accuracy: 0.5317\n",
      "Epoch 22/25\n",
      "661/661 [==============================] - 36s 54ms/step - loss: 0.1762 - accuracy: 1.0000 - val_loss: 1.0797 - val_accuracy: 0.5556\n",
      "Epoch 23/25\n",
      "661/661 [==============================] - 35s 52ms/step - loss: 0.1721 - accuracy: 1.0000 - val_loss: 1.1487 - val_accuracy: 0.5476\n",
      "Epoch 24/25\n",
      "661/661 [==============================] - 38s 57ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 1.1503 - val_accuracy: 0.5397\n",
      "Epoch 25/25\n",
      "661/661 [==============================] - 34s 51ms/step - loss: 0.1649 - accuracy: 1.0000 - val_loss: 1.2646 - val_accuracy: 0.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 661 samples, validate on 126 samples\n",
      "Epoch 1/25\n",
      "661/661 [==============================] - 48s 73ms/step - loss: 2.2701 - accuracy: 0.5658 - val_loss: 2.0438 - val_accuracy: 0.5238\n",
      "Epoch 2/25\n",
      "661/661 [==============================] - 45s 69ms/step - loss: 1.8504 - accuracy: 0.5658 - val_loss: 1.6765 - val_accuracy: 0.5238\n",
      "Epoch 3/25\n",
      "661/661 [==============================] - 45s 68ms/step - loss: 1.5152 - accuracy: 0.5658 - val_loss: 1.4152 - val_accuracy: 0.5238\n",
      "Epoch 4/25\n",
      "661/661 [==============================] - 47s 72ms/step - loss: 1.2908 - accuracy: 0.7005 - val_loss: 1.2302 - val_accuracy: 0.5238\n",
      "Epoch 5/25\n",
      "661/661 [==============================] - 49s 75ms/step - loss: 1.0671 - accuracy: 0.7685 - val_loss: 1.1086 - val_accuracy: 0.5238\n",
      "Epoch 6/25\n",
      "661/661 [==============================] - 47s 72ms/step - loss: 0.8559 - accuracy: 0.9501 - val_loss: 1.0263 - val_accuracy: 0.5476\n",
      "Epoch 7/25\n",
      "661/661 [==============================] - 46s 69ms/step - loss: 0.6965 - accuracy: 0.9955 - val_loss: 1.0311 - val_accuracy: 0.5714\n",
      "Epoch 8/25\n",
      "661/661 [==============================] - 47s 71ms/step - loss: 0.5725 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.5079\n",
      "Epoch 9/25\n",
      "661/661 [==============================] - 46s 70ms/step - loss: 0.4906 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.4841\n",
      "Epoch 10/25\n",
      "661/661 [==============================] - 46s 70ms/step - loss: 0.4405 - accuracy: 1.0000 - val_loss: 1.0373 - val_accuracy: 0.4921\n",
      "Epoch 11/25\n",
      "661/661 [==============================] - 51s 78ms/step - loss: 0.4108 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.4841\n",
      "Epoch 12/25\n",
      "661/661 [==============================] - 49s 74ms/step - loss: 0.3882 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.4921\n",
      "Epoch 13/25\n",
      "661/661 [==============================] - 53s 80ms/step - loss: 0.3695 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.4921\n",
      "Epoch 14/25\n",
      "661/661 [==============================] - 45s 68ms/step - loss: 0.3537 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.4841\n",
      "Epoch 15/25\n",
      "661/661 [==============================] - 49s 74ms/step - loss: 0.3398 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.5000\n",
      "Epoch 16/25\n",
      "661/661 [==============================] - 47s 72ms/step - loss: 0.3274 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.5079\n",
      "Epoch 17/25\n",
      "661/661 [==============================] - 50s 76ms/step - loss: 0.3163 - accuracy: 1.0000 - val_loss: 0.9697 - val_accuracy: 0.4841\n",
      "Epoch 18/25\n",
      "661/661 [==============================] - 47s 71ms/step - loss: 0.3061 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.4921\n",
      "Epoch 19/25\n",
      "661/661 [==============================] - 52s 79ms/step - loss: 0.2970 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 0.4841\n",
      "Epoch 20/25\n",
      "661/661 [==============================] - 51s 77ms/step - loss: 0.2882 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.4683\n",
      "Epoch 21/25\n",
      "661/661 [==============================] - 49s 74ms/step - loss: 0.2798 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.4762\n",
      "Epoch 22/25\n",
      "661/661 [==============================] - 46s 70ms/step - loss: 0.2721 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.4841\n",
      "Epoch 23/25\n",
      "661/661 [==============================] - 46s 70ms/step - loss: 0.2650 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.4683\n",
      "Epoch 24/25\n",
      "661/661 [==============================] - 46s 70ms/step - loss: 0.2579 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.4683\n",
      "Epoch 25/25\n",
      "661/661 [==============================] - 45s 68ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.4841\n",
      "Train on 661 samples, validate on 126 samples\n",
      "Epoch 1/25\n",
      "661/661 [==============================] - 42s 63ms/step - loss: 0.6956 - accuracy: 0.5386 - val_loss: 0.6893 - val_accuracy: 0.5238\n",
      "Epoch 2/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.6753 - accuracy: 0.5673 - val_loss: 0.6927 - val_accuracy: 0.5079\n",
      "Epoch 3/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.6606 - accuracy: 0.6203 - val_loss: 0.6926 - val_accuracy: 0.5317\n",
      "Epoch 4/25\n",
      "661/661 [==============================] - 39s 58ms/step - loss: 0.6429 - accuracy: 0.6475 - val_loss: 0.6894 - val_accuracy: 0.5476\n",
      "Epoch 5/25\n",
      "661/661 [==============================] - 40s 60ms/step - loss: 0.6172 - accuracy: 0.6899 - val_loss: 0.6930 - val_accuracy: 0.5952\n",
      "Epoch 6/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.5922 - accuracy: 0.7080 - val_loss: 0.6929 - val_accuracy: 0.5794\n",
      "Epoch 7/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.5506 - accuracy: 0.7458 - val_loss: 0.7184 - val_accuracy: 0.5476\n",
      "Epoch 8/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.5171 - accuracy: 0.7700 - val_loss: 0.7588 - val_accuracy: 0.5714\n",
      "Epoch 9/25\n",
      "661/661 [==============================] - 40s 60ms/step - loss: 0.4542 - accuracy: 0.8033 - val_loss: 0.7568 - val_accuracy: 0.5317\n",
      "Epoch 10/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.3993 - accuracy: 0.8427 - val_loss: 0.8864 - val_accuracy: 0.5714\n",
      "Epoch 11/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.3311 - accuracy: 0.8896 - val_loss: 0.9479 - val_accuracy: 0.5556\n",
      "Epoch 12/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.2553 - accuracy: 0.9244 - val_loss: 0.9785 - val_accuracy: 0.5317\n",
      "Epoch 13/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.1818 - accuracy: 0.9561 - val_loss: 1.1994 - val_accuracy: 0.5317\n",
      "Epoch 14/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.1239 - accuracy: 0.9788 - val_loss: 1.1854 - val_accuracy: 0.5159\n",
      "Epoch 15/25\n",
      "661/661 [==============================] - 39s 60ms/step - loss: 0.0711 - accuracy: 0.9894 - val_loss: 1.4523 - val_accuracy: 0.5397\n",
      "Epoch 16/25\n",
      "661/661 [==============================] - 47s 71ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 1.5705 - val_accuracy: 0.5397\n",
      "Epoch 17/25\n",
      "661/661 [==============================] - 40s 60ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.6510 - val_accuracy: 0.5238\n",
      "Epoch 18/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.0244 - accuracy: 0.9970 - val_loss: 1.6445 - val_accuracy: 0.5079\n",
      "Epoch 19/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.0163 - accuracy: 0.9985 - val_loss: 1.7282 - val_accuracy: 0.5000\n",
      "Epoch 20/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.0988 - accuracy: 0.9652 - val_loss: 1.5135 - val_accuracy: 0.5000\n",
      "Epoch 21/25\n",
      "661/661 [==============================] - 38s 58ms/step - loss: 0.0744 - accuracy: 0.9773 - val_loss: 1.5407 - val_accuracy: 0.5476\n",
      "Epoch 22/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.0275 - accuracy: 0.9970 - val_loss: 1.7732 - val_accuracy: 0.5317\n",
      "Epoch 23/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.8922 - val_accuracy: 0.5079\n",
      "Epoch 24/25\n",
      "661/661 [==============================] - 39s 59ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.9603 - val_accuracy: 0.5238\n",
      "Epoch 25/25\n",
      "661/661 [==============================] - 42s 63ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0363 - val_accuracy: 0.5159\n",
      "Train on 661 samples, validate on 126 samples\n",
      "Epoch 1/25\n",
      "661/661 [==============================] - 46s 69ms/step - loss: 0.6947 - accuracy: 0.5280 - val_loss: 0.7009 - val_accuracy: 0.5317\n",
      "Epoch 2/25\n",
      "661/661 [==============================] - 43s 65ms/step - loss: 0.6754 - accuracy: 0.5749 - val_loss: 0.7022 - val_accuracy: 0.5317\n",
      "Epoch 3/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.6814 - accuracy: 0.5809 - val_loss: 0.6846 - val_accuracy: 0.5556\n",
      "Epoch 4/25\n",
      "661/661 [==============================] - 43s 64ms/step - loss: 0.6678 - accuracy: 0.5870 - val_loss: 0.6894 - val_accuracy: 0.5714\n",
      "Epoch 5/25\n",
      "661/661 [==============================] - 47s 71ms/step - loss: 0.6538 - accuracy: 0.5915 - val_loss: 0.6800 - val_accuracy: 0.5556\n",
      "Epoch 6/25\n",
      "661/661 [==============================] - 43s 65ms/step - loss: 0.6495 - accuracy: 0.6263 - val_loss: 0.6764 - val_accuracy: 0.5952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "661/661 [==============================] - 43s 65ms/step - loss: 0.6342 - accuracy: 0.6520 - val_loss: 0.6856 - val_accuracy: 0.5873\n",
      "Epoch 8/25\n",
      "661/661 [==============================] - 42s 63ms/step - loss: 0.6299 - accuracy: 0.6278 - val_loss: 0.6712 - val_accuracy: 0.6032\n",
      "Epoch 9/25\n",
      "661/661 [==============================] - 43s 65ms/step - loss: 0.6258 - accuracy: 0.6596 - val_loss: 0.6715 - val_accuracy: 0.5635\n",
      "Epoch 10/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.6218 - accuracy: 0.6596 - val_loss: 0.6739 - val_accuracy: 0.5873\n",
      "Epoch 11/25\n",
      "661/661 [==============================] - 43s 65ms/step - loss: 0.6077 - accuracy: 0.6551 - val_loss: 0.6686 - val_accuracy: 0.5794\n",
      "Epoch 12/25\n",
      "661/661 [==============================] - 44s 66ms/step - loss: 0.5965 - accuracy: 0.7020 - val_loss: 0.6678 - val_accuracy: 0.6190\n",
      "Epoch 13/25\n",
      "661/661 [==============================] - 43s 66ms/step - loss: 0.5718 - accuracy: 0.7126 - val_loss: 0.6691 - val_accuracy: 0.6032\n",
      "Epoch 14/25\n",
      "661/661 [==============================] - 42s 63ms/step - loss: 0.5795 - accuracy: 0.7080 - val_loss: 0.6720 - val_accuracy: 0.6429\n",
      "Epoch 15/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.5600 - accuracy: 0.7171 - val_loss: 0.6830 - val_accuracy: 0.5873\n",
      "Epoch 16/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.5405 - accuracy: 0.7610 - val_loss: 0.6812 - val_accuracy: 0.6032\n",
      "Epoch 17/25\n",
      "661/661 [==============================] - 41s 62ms/step - loss: 0.5496 - accuracy: 0.7020 - val_loss: 0.6867 - val_accuracy: 0.6032\n",
      "Epoch 18/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.5195 - accuracy: 0.7670 - val_loss: 0.6911 - val_accuracy: 0.6429\n",
      "Epoch 19/25\n",
      "661/661 [==============================] - 49s 74ms/step - loss: 0.5128 - accuracy: 0.7640 - val_loss: 0.7000 - val_accuracy: 0.6111\n",
      "Epoch 20/25\n",
      "661/661 [==============================] - 42s 64ms/step - loss: 0.4997 - accuracy: 0.7564 - val_loss: 0.7048 - val_accuracy: 0.6349\n",
      "Epoch 21/25\n",
      "661/661 [==============================] - 44s 67ms/step - loss: 0.4845 - accuracy: 0.7700 - val_loss: 0.7078 - val_accuracy: 0.6190\n",
      "Epoch 22/25\n",
      "661/661 [==============================] - 44s 66ms/step - loss: 0.4704 - accuracy: 0.7806 - val_loss: 0.7279 - val_accuracy: 0.6032\n",
      "Epoch 23/25\n",
      "661/661 [==============================] - 46s 69ms/step - loss: 0.4340 - accuracy: 0.8033 - val_loss: 0.7419 - val_accuracy: 0.5873\n",
      "Epoch 24/25\n",
      "661/661 [==============================] - 48s 72ms/step - loss: 0.4632 - accuracy: 0.7943 - val_loss: 0.7824 - val_accuracy: 0.5476\n",
      "Epoch 25/25\n",
      "661/661 [==============================] - 45s 68ms/step - loss: 0.4190 - accuracy: 0.8260 - val_loss: 0.7718 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Dow training\")\n",
    "history_Dow=model_0().fit([X_dowp_train[:,500:2000],np.reshape(X_dowp_train[:,2000:],(len(X_dowp_train),6,1))], y_dowp_train['Up_Dow'], epochs=25, validation_split =0.16,verbose=1)\n",
    "history_Dow_1=model_1().fit([X_dowp_train[:,500:2000],np.reshape(X_dowp_train[:,2000:],(len(X_dowp_train),6,1))], y_dowp_train['Up_Dow'], epochs=25, validation_split =0.16,verbose=1)\n",
    "history_Dow_2=model_2().fit([X_dowp_train[:,:500],X_dowp_train[:,500:2000],np.reshape(X_dowp_train[:,2000:],(len( X_dowp_train),6,1))], y_dowp_train, epochs=25, batch_size=28, validation_split=0.16,verbose=1)\n",
    "history_Dow_3=model_3().fit([X_dowp_train[:,:500],X_dowp_train[:,500:2000],np.reshape(X_dowp_train[:,2000:],(len( X_dowp_train),6,1))], y_dowp_train, epochs=25, batch_size=28, validation_split=0.16,verbose=1)\n",
    "history_Dow_4=model_4().fit([X_dowp_train[:,:500],X_dowp_train[:,500:2000],np.reshape(X_dowp_train[:,2000:],(len( X_dowp_train),6,1))], y_dowp_train, epochs=25, batch_size=28, validation_split=0.16,verbose=1)\n",
    "\n",
    "\n",
    "#Dow comparison\n",
    "acc_Dow = history_Dow.history['accuracy']\n",
    "val_acc_Dow = history_Dow.history['val_accuracy']\n",
    "acc_Dow_1 = history_Dow_1.history['accuracy']\n",
    "val_acc_Dow_1 = history_Dow_1.history['val_accuracy']\n",
    "acc_Dow_2 = history_Dow_2.history['accuracy']\n",
    "val_acc_Dow_2 = history_Dow_2.history['val_accuracy']\n",
    "acc_Dow_3 = history_Dow_3.history['accuracy']\n",
    "val_acc_Dow_3 = history_Dow_3.history['val_accuracy']\n",
    "acc_Dow_4 = history_Dow_4.history['accuracy']\n",
    "val_acc_Dow_4 = history_Dow_4.history['val_accuracy']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc_Dow) + 1)\n",
    "#plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_Dow, label='Val dow lvl0')\n",
    "plt.plot(epochs, val_acc_Dow_1, label='Val dow lvl1')\n",
    "plt.plot(epochs, val_acc_Dow_2, label='Val dow lvl2')\n",
    "plt.plot(epochs, val_acc_Dow_3, label='Val dow lvl3')\n",
    "plt.plot(epochs, val_acc_Dow_4, label='Val dow lvl4')\n",
    "plt.title('validation comparison for dow')\n",
    "plt.legend()\n",
    "#plt.figure()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
