{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                               link  \\\n",
      "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
      "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
      "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
      "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
      "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
      "\n",
      "                                             content                 date  \\\n",
      "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
      "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
      "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
      "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
      "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
      "\n",
      "   retweets  favorites mentions hashtags  \n",
      "0       510        917      NaN      NaN  \n",
      "1        34        267      NaN      NaN  \n",
      "2        13         19      NaN      NaN  \n",
      "3        11         26      NaN      NaN  \n",
      "4      1375       1945      NaN      NaN  \n",
      "       id ticker                                              title category  \\\n",
      "0  221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
      "1  221516    NIO  NIO only consumer gainer  Workhorse Group amon...     news   \n",
      "2  221517    NIO  NIO leads consumer gainers  Beyond Meat and Ma...     news   \n",
      "3  221518    NIO                  NIO  NVAX among premarket gainers     news   \n",
      "4  221519    NIO                  PLUG  NIO among premarket gainers     news   \n",
      "\n",
      "                                             content release_date  \\\n",
      "0  What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
      "1  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
      "2  Gainers  NIO  NYSE NIO   14   Village Farms In...   2020-01-15   \n",
      "3  Cemtrex  NASDAQ CETX   85  after FY results \\n...   2020-01-15   \n",
      "4  aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   2020-01-06   \n",
      "\n",
      "          provider                                                url  \\\n",
      "0  The Motley Fool                             https://invst.ly/pigqi   \n",
      "1    Seeking Alpha                             https://invst.ly/pje9c   \n",
      "2    Seeking Alpha                             https://invst.ly/pifmv   \n",
      "3    Seeking Alpha                             https://invst.ly/picu8   \n",
      "4    Seeking Alpha  https://seekingalpha.com/news/3529772-plug-nio...   \n",
      "\n",
      "   article_id  \n",
      "0     2060327  \n",
      "1     2062196  \n",
      "2     2060249  \n",
      "3     2060039  \n",
      "4     2053096  \n",
      "   Unnamed: 0        date      timestamp  \\\n",
      "0           0  2012/10/01  1349064000000   \n",
      "1           1  2012/10/01  1349064000000   \n",
      "2           2  2012/10/01  1349064000000   \n",
      "3           3  2012/10/01  1349064000000   \n",
      "4           4  2012/10/01  1349064000000   \n",
      "\n",
      "                                               title  level2  level3  \n",
      "0  Catchings, January help Fever even series with...  sports    wnba  \n",
      "1  Kyle Busch rants on radio after his Toyota fal...  sports  nascar  \n",
      "2  Schwarzenegger says 'You can't run from your m...    life   books  \n",
      "3                                    Ryder Cup Day 3  sports    golf  \n",
      "4  Regular officials blow another big call agains...  gameon     NaN  \n",
      "         Date     Open    High      Low    Close  Adj Close    Volume\n",
      "0  2016-11-01  4802.75  4817.0  4718.75  4757.25    4757.25  307806.0\n",
      "1  2016-11-02  4754.50  4768.5  4708.25  4716.75    4716.75  300313.0\n",
      "2  2016-11-03  4700.00  4729.5  4668.25  4674.50    4674.50  280599.0\n",
      "3  2016-11-04  4671.25  4695.5  4651.25  4657.75    4657.75  264048.0\n",
      "4  2016-11-06      NaN     NaN      NaN      NaN        NaN       NaN\n",
      "         Date          Open          High           Low         Close  \\\n",
      "0  2016-11-01  18158.240234  18177.009766  17940.839844  18037.099609   \n",
      "1  2016-11-02  18017.720703  18044.150391  17931.890625  17959.640625   \n",
      "2  2016-11-03  17978.750000  18006.960938  17904.070313  17930.669922   \n",
      "3  2016-11-04  17928.349609  17986.759766  17883.560547  17888.279297   \n",
      "4  2016-11-07  17994.640625  18263.300781  17994.640625  18259.599609   \n",
      "\n",
      "      Adj Close     Volume  \n",
      "0  18037.099609  101280000  \n",
      "1  17959.640625   88610000  \n",
      "2  17930.669922   77860000  \n",
      "3  17888.279297   97760000  \n",
      "4  18259.599609   93450000  \n",
      "         Date     Open     High      Low    Close  Adj Close     Volume\n",
      "0  2016-11-01  2123.50  2129.50  2091.00  2103.75    2103.75  2257062.0\n",
      "1  2016-11-02  2102.25  2106.50  2087.25  2092.25    2092.25  2013595.0\n",
      "2  2016-11-03  2088.25  2098.75  2079.75  2083.50    2083.50  1795490.0\n",
      "3  2016-11-04  2084.00  2094.25  2078.75  2080.00    2080.00  2079129.0\n",
      "4  2016-11-06      NaN      NaN      NaN      NaN        NaN        NaN\n",
      "        Date                                              title\n",
      "0 2020-01-15  Why Shares of Chinese Electric Car Maker NIO A...\n",
      "1 2020-01-18  NIO only consumer gainer  Workhorse Group amon...\n",
      "4 2020-01-06  PLUG  NIO among premarket gainers. NIO up 6  o...\n",
      "5 2019-12-31  NIO leads consumer gainers  Origin Agritech on...\n",
      "6 2020-01-07  Beyond Meat tops consumer gainers  NIO and Eas...\n",
      "         date                                              title  level2\n",
      "0  2012/10/01  Catchings, January help Fever even series with...  sports\n",
      "1  2012/10/01  Kyle Busch rants on radio after his Toyota fal...  sports\n",
      "2  2012/10/01  Schwarzenegger says 'You can't run from your m...    life\n",
      "3  2012/10/01                                    Ryder Cup Day 3  sports\n",
      "4  2012/10/01  Regular officials blow another big call agains...  gameon\n",
      "             Date                                              title\n",
      "566274 2016-11-08  FTC sends $3.7M to victims of pyramid scheme. ...\n",
      "566747 2016-11-09  Trump website glitch fixed, but not before Int...\n",
      "567390 2016-11-10  Every bit of positivity counts. Here's how to ...\n",
      "567966 2016-11-11  Student gives 'deportation' notices to other k...\n",
      "568476 2016-11-12  Clintons are a 'talented family,' Trump tells ...\n",
      "            Date                                            content\n",
      "30887 2016-11-08  Today we are going to win the great state of M...\n",
      "30897 2016-11-09  Such a beautiful and important evening! The fo...\n",
      "30898 2016-11-10  Happy 241st birthday to the U.S. Marine Corps!...\n",
      "30901 2016-11-11  Love the fact that the small groups of protest...\n",
      "30904 2016-11-12  This will prove to be a great time in the live...\n",
      "         Date  Up_sp\n",
      "6  2016-11-07      1\n",
      "7  2016-11-08      1\n",
      "8  2016-11-09      1\n",
      "10 2016-11-13      0\n",
      "11 2016-11-14      1\n",
      "         Date  Close_sp\n",
      "6  2016-11-07   2135.50\n",
      "7  2016-11-08   2160.25\n",
      "8  2016-11-09   2167.25\n",
      "10 2016-11-13   2160.50\n",
      "11 2016-11-14   2179.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model for each stock\n",
      "Dow:  0.5590851334180432\n",
      "sp:  0.5933926302414231\n",
      "nas:  0.5921219822109276\n",
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "path=\"C:\\\\Users\\\\marwe\\\\Desktop\\\\Trump_tweet_news_stock\"\n",
    "#read trump tweets\n",
    "df_tweets=pd.read_csv(path+\"\\\\realdonaldtrump.csv\")\n",
    "print(df_tweets.head())\n",
    "\n",
    "\n",
    "#stock news\n",
    "df_stock_news=pd.read_csv(\"C:\\\\Users\\\\marwe\\\\Desktop\\\\LaTeX JOTA\\\\us_equities_news_dataset.csv\")\n",
    "print(df_stock_news.head())\n",
    "\n",
    "#read the news dataset from usa today\n",
    "df_news=pd.read_csv(path+\"\\\\USA Today.csv\")\n",
    "print(df_news.head())\n",
    "\n",
    "#read nasdaq, s&p500 and dow\n",
    "\n",
    "df_nasdaq=pd.read_csv(path+\"\\\\NASDAQ_price.csv\")\n",
    "print(df_nasdaq.head())\n",
    "\n",
    "\n",
    "\n",
    "df_Dow=pd.read_csv(path+\"\\\\DowJones_price.csv\")\n",
    "print(df_Dow.head())\n",
    "\n",
    "df_sp=pd.read_csv(\"C:\\\\Users\\\\marwe\\\\Desktop\\\\Trump_tweet_news_stock\\\\SP_price.csv\")\n",
    "print(df_sp.head())\n",
    "\n",
    "\n",
    "\n",
    "#preparing the news dataset\n",
    "'''\n",
    "we will first rearrange the news then add columns for the stock market\n",
    "dates are between election and 2020-04-03 (one day after the news stop)\n",
    "\n",
    "'''\n",
    "\n",
    "df_stock_news=df_stock_news.rename(columns={\"release_date\":\"Date\"})\n",
    "df_stock_news['Date'] = pd.to_datetime(df_stock_news['Date']) \n",
    "df_stock_news['Date'] = pd.to_datetime(df_stock_news['Date']) \n",
    "mask = (df_stock_news['Date'] >= '2016-11-8' )\n",
    "df_stock_news=df_stock_news.loc[mask]\n",
    "col=['Date','title']\n",
    "df_stock_news=df_stock_news[col]\n",
    "\n",
    "#df_stock_news.content = np.where(df_stock_news.content.isnull(),str(df_stock_news.Date),str(df_stock_news.content))\n",
    "#toronto_df['Neighbourhood'] = toronto_df.groupby(['Postcode','Borough'])['Neighbourhood'].agg(lambda x: ','.join(x))\n",
    "\n",
    "df_stock_news['title']=df_stock_news['title'].fillna(\" \")\n",
    "df_stock_news['title'] = df_stock_news[['Date','title']].groupby(['Date'])['title'].transform(lambda x: '. '.join(x))\n",
    "df_stock_news=df_stock_news[['Date','title']].drop_duplicates()\n",
    "print(df_stock_news.head())\n",
    "\n",
    "#col_selection=[\"news\",\"money\",\"onpolitics\",\"theoval\"]\n",
    "col=['date','title','level2']\n",
    "df_news=df_news[col]\n",
    "print(df_news.head())\n",
    "#df_news=df_news.loc[df_news['level2'] != 'sports']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'entertainment']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'travel']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'gameon']\n",
    "#df_news=df_news.loc[df_news['level2'] != 'music']\n",
    "df_news=df_news.loc[(df_news['level2'] == \"news\")|(df_news['level2'] == \"money\")|(df_news['level2'] == \"onpolitics\")|(df_news['level2'] == \"theoval\")]\n",
    "#pick between the dates needed\n",
    "df_news=df_news.rename(columns={\"date\":\"Date\"})\n",
    "df_news['Date'] = pd.to_datetime(df_news['Date']) \n",
    "mask = (df_news['Date'] >= '2016-11-8' )\n",
    "df_news=df_news.loc[mask]\n",
    "col=['Date','title']\n",
    "df_news=df_news[col]\n",
    "df_news['title'] = df_news[['Date','title']].groupby(['Date'])['title'].transform(lambda x: '. '.join(x))\n",
    "df_news=df_news[['Date','title']].drop_duplicates()\n",
    "print(df_news.head())\n",
    "\n",
    "def sub_one(x):\n",
    "\treturn x -timedelta(days=1)\n",
    "\n",
    "#make sure dow nasdaq and s&p are recorded between the 2 dates\n",
    "#dow\n",
    "df_Dow['Date'] = pd.to_datetime(df_Dow['Date']) \n",
    "mask = (df_Dow['Date'] >= '2016-11-8') &  (df_Dow['Date'] <= '2020-4-3')\n",
    "df_Dow=df_Dow.loc[mask]\n",
    "colo=['Date','Open','Close','Adj Close']\n",
    "df_Dow=df_Dow[colo]\n",
    "df_Dow['Adj Close']=np.where(df_Dow['Close']>=df_Dow['Open'],1,0)\n",
    "df_Dow=df_Dow.rename(columns={\"Adj Close\":\"Up_Dow\"})\n",
    "df_Dow=df_Dow.rename(columns={\"Close\":\"Close_Dow\"})\n",
    "df_Dow['Date']=df_Dow['Date'].apply(sub_one)\n",
    "\n",
    "#col_Dow=['Date','Up_Dow']\n",
    "#df_Dow=df_Dow.loc[col_Dow]\n",
    "\n",
    "\n",
    "#nasdaq\n",
    "df_nasdaq['Date'] = pd.to_datetime(df_nasdaq['Date']) \n",
    "mask = (df_nasdaq['Date'] >= '2016-11-8') &  (df_nasdaq['Date'] <= '2020-4-3')\n",
    "df_nasdaq=df_nasdaq.loc[mask]\n",
    "df_nasdaq=df_nasdaq.dropna()\n",
    "df_nasdaq=df_nasdaq[colo]\n",
    "df_nasdaq['Adj Close']=np.where(df_nasdaq['Close']>=df_nasdaq['Open'],1,0)\n",
    "df_nasdaq=df_nasdaq.rename(columns={\"Adj Close\":\"Up_nas\"})\n",
    "df_nasdaq=df_nasdaq.rename(columns={\"Close\":\"Close_nas\"})\n",
    "df_nasdaq['Date']=df_nasdaq['Date'].apply(sub_one)\n",
    "#col_nasdaq=['Date','Close_nas','Up_nas']\n",
    "#df_nasdaq=df_nasdaq.loc[col_nasdaq]\n",
    "\n",
    "#SP\n",
    "df_sp['Date'] = pd.to_datetime(df_sp['Date']) \n",
    "mask = (df_sp['Date'] >= '2016-11-8') &  (df_sp['Date'] <= '2020-4-3')\n",
    "df_sp=df_sp.loc[mask]\n",
    "df_sp=df_sp.dropna()\n",
    "df_sp=df_sp[colo]\n",
    "df_sp['Adj Close']=np.where(df_sp['Close']>=df_sp['Open'],1,0)\n",
    "df_sp=df_sp.rename(columns={\"Adj Close\":\"Up_sp\"})\n",
    "df_sp=df_sp.rename(columns={\"Close\":\"Close_sp\"})\n",
    "df_sp['Date']=df_sp['Date'].apply(sub_one)\n",
    "\n",
    "#col_sp=['Date','Close_sp','Up_sp']\n",
    "#df_sp=df_sp.loc[col_sp]\n",
    "\n",
    "#trying merge\n",
    "margo=pd.merge(df_news, df_Dow, how='outer', on='Date')\n",
    "margo=pd.merge(margo,df_nasdaq, how='outer', on='Date')\n",
    "df_news_pred=pd.merge(margo,df_sp, how='outer', on='Date')\n",
    "df_news_pred=pd.merge(df_news_pred,df_stock_news, how='outer', on='Date')\n",
    "\n",
    "\n",
    "\n",
    "col_margo=['Date','title_x','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp','title_y']\n",
    "df_news_pred=df_news_pred[col_margo]\n",
    "df_news_pred=df_news_pred.dropna()\n",
    "df_news_pred['title_x'] = df_news_pred[['Date','title_x','title_y']].groupby(['Date'])['title_x'].transform(lambda x: '. '.join(x))\n",
    "col_margo=['Date','title_x','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp']\n",
    "df_news_pred=df_news_pred[col_margo]\n",
    "\n",
    "'''\n",
    "we created df_news_pred, a dataset that has daily news headlines as input and next day stock market prediction\n",
    "we will use this data to predict the stock market using possibly RNN \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Now we do the same for trump tweets\n",
    "'''\n",
    "#initial preprocessing and selecting the dates\n",
    "df_tweets=df_tweets.rename(columns={\"date\":\"Date\"})\n",
    "df_tweets['Date'] = pd.to_datetime(df_tweets['Date']) \n",
    "df_tweets = df_tweets.assign(Date = lambda x: pd.to_datetime(x['Date'].dt.strftime('%Y-%m-%d')))\n",
    "mask = (df_tweets['Date'] >= '2016-11-8') &  (df_tweets['Date'] <= '2020-4-3')\n",
    "df_tweets=df_tweets.loc[mask]\n",
    "\n",
    "\n",
    "#merge tweets according to date\n",
    "df_tweets['content'] = df_tweets[['Date','content']].groupby(['Date'])['content'].transform(lambda x: '. '.join(x))\n",
    "df_tweets=df_tweets[['Date','content']].drop_duplicates()\n",
    "print(df_tweets.head())\n",
    "\n",
    "#construct the input/output table with next day prediction\n",
    "margo=pd.merge(df_tweets, df_Dow, how='outer', on='Date')\n",
    "margo=pd.merge(margo,df_nasdaq, how='outer', on='Date')\n",
    "df_tweet_pred=pd.merge(margo,df_sp, how='outer', on='Date')\n",
    "\n",
    "col_margo=['Date','content','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp']\n",
    "df_tweet_pred=df_tweet_pred[col_margo]\n",
    "df_tweet_pred=df_tweet_pred.dropna()\n",
    "\n",
    "\n",
    "'''\n",
    "we created df_tweet_pred, a dataset that has daily trump tweets as input and next day stock market prediction\n",
    "we will use this data to predict the stock market using possibly RNN \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "now we prepare the time series data, we want the data to look like the following\n",
    "5 past observations of stock market info as input and then todays market info as output\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# up an down table for sp\n",
    "\n",
    "df_sp_his=pd.DataFrame()\n",
    "df_sp_his['Date']=df_sp['Date']\n",
    "df_sp_his['Up_sp']=df_sp['Up_sp']\n",
    "print(df_sp_his.head())\n",
    "df_sp_his['t-1sp']=df_sp['Up_sp'].shift(1)\n",
    "df_sp_his['t-2sp']=df_sp['Up_sp'].shift(2)\n",
    "df_sp_his['t-3sp']=df_sp['Up_sp'].shift(3)\n",
    "df_sp_his['t-4sp']=df_sp['Up_sp'].shift(4)\n",
    "df_sp_his['t-5sp']=df_sp['Up_sp'].shift(5)\n",
    "df_sp_his['t-6sp']=df_sp['Up_sp'].shift(6)\n",
    "\n",
    "# up an down table for Dow\n",
    "df_dow_his=pd.DataFrame()\n",
    "df_dow_his['Date']=df_Dow['Date']\n",
    "df_dow_his['Up_Dow']=df_Dow['Up_Dow']\n",
    "df_dow_his['t-1Dow']=df_Dow['Up_Dow'].shift(1)\n",
    "df_dow_his['t-2Dow']=df_Dow['Up_Dow'].shift(2)\n",
    "df_dow_his['t-3Dow']=df_Dow['Up_Dow'].shift(3)\n",
    "df_dow_his['t-4Dow']=df_Dow['Up_Dow'].shift(4)\n",
    "df_dow_his['t-5Dow']=df_Dow['Up_Dow'].shift(5)\n",
    "df_dow_his['t-6Dow']=df_Dow['Up_Dow'].shift(6)\n",
    "\n",
    "# up an down table for nasdaq\n",
    "df_nas_his=pd.DataFrame()\n",
    "df_nas_his['Date']=df_nasdaq['Date']\n",
    "df_nas_his['Up_nas']=df_nasdaq['Up_nas']\n",
    "df_nas_his['t-1nas']=df_nasdaq['Up_nas'].shift(1)\n",
    "df_nas_his['t-2nas']=df_nasdaq['Up_nas'].shift(2)\n",
    "df_nas_his['t-3nas']=df_nasdaq['Up_nas'].shift(3)\n",
    "df_nas_his['t-4nas']=df_nasdaq['Up_nas'].shift(4)\n",
    "df_nas_his['t-5nas']=df_nasdaq['Up_nas'].shift(5)\n",
    "df_nas_his['t-6nas']=df_nasdaq['Up_nas'].shift(6)\n",
    "\n",
    "\n",
    "#same for the price\n",
    "\n",
    "# price table for sp\n",
    "df_spp_his=pd.DataFrame()\n",
    "df_spp_his['Date']=df_sp['Date']\n",
    "df_spp_his['Close_sp']=df_sp['Close_sp']\n",
    "print(df_spp_his.head())\n",
    "df_spp_his['t-1spp']=df_sp['Close_sp'].shift(1)\n",
    "df_spp_his['t-2spp']=df_sp['Close_sp'].shift(2)\n",
    "df_spp_his['t-3spp']=df_sp['Close_sp'].shift(3)\n",
    "df_spp_his['t-4spp']=df_sp['Close_sp'].shift(4)\n",
    "df_spp_his['t-5spp']=df_sp['Close_sp'].shift(5)\n",
    "df_spp_his['t-6spp']=df_sp['Close_sp'].shift(6)\n",
    "\n",
    "# price for Dow\n",
    "df_dowp_his=pd.DataFrame()\n",
    "df_dowp_his['Date']=df_Dow['Date']\n",
    "df_dowp_his['Close_Dow']=df_Dow['Close_Dow']\n",
    "df_dowp_his['t-1Dowp']=df_Dow['Close_Dow'].shift(1)\n",
    "df_dowp_his['t-2Dowp']=df_Dow['Close_Dow'].shift(2)\n",
    "df_dowp_his['t-3Dowp']=df_Dow['Close_Dow'].shift(3)\n",
    "df_dowp_his['t-4Dowp']=df_Dow['Close_Dow'].shift(4)\n",
    "df_dowp_his['t-5Dowp']=df_Dow['Close_Dow'].shift(5)\n",
    "df_dowp_his['t-6Dowp']=df_Dow['Close_Dow'].shift(6)\n",
    "\n",
    "# price for nasdaq\n",
    "df_nasp_his=pd.DataFrame()\n",
    "df_nasp_his['Date']=df_nasdaq['Date']\n",
    "df_nasp_his['Close_nas']=df_nasdaq['Close_nas']\n",
    "df_nasp_his['t-1nasp']=df_nasdaq['Close_nas'].shift(1)\n",
    "df_nasp_his['t-2nasp']=df_nasdaq['Close_nas'].shift(2)\n",
    "df_nasp_his['t-3nasp']=df_nasdaq['Close_nas'].shift(3)\n",
    "df_nasp_his['t-4nasp']=df_nasdaq['Close_nas'].shift(4)\n",
    "df_nasp_his['t-5nasp']=df_nasdaq['Close_nas'].shift(5)\n",
    "df_nasp_his['t-6nasp']=df_nasdaq['Close_nas'].shift(6)\n",
    "\n",
    "'''\n",
    "lets recap the input we got so far:\n",
    "df_news_pred: has daily news headlines and market predictions for sp/dow/nas\n",
    "df_tweet_pred: has daily trump tweets and then market predictions\n",
    "\n",
    "lastly we have time series data for nas/sp/dow for ups downs and prices (6 datasets in total)\n",
    "\n",
    "a total of 8 useful datasets, need to figure out a way to clean it further and construct a model\n",
    "'''\n",
    "\n",
    "'''\n",
    "lets try to merge some stuff\n",
    "'''\n",
    "\n",
    "merge_twt_news=pd.merge(df_tweet_pred,df_news_pred, how='outer', on=['Date','Close_Dow','Up_Dow','Close_nas','Up_nas','Close_sp','Up_sp'])\n",
    "#merge_twt_news=pd.merge(merge_twt_news,df_sp_his, how='outer', on=['Date','Up_sp'])\n",
    "#merge_twt_news=pd.merge(merge_twt_news,df_nas_his, how='outer', on=['Date','Up_nas'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_sp_his, how='outer', on=['Date','Up_sp'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_dow_his, how='outer', on=['Date','Up_Dow'])\n",
    "merge_twt_news=pd.merge(merge_twt_news,df_nas_his, how='outer', on=['Date','Up_nas'])\n",
    "\n",
    "merge_twt_news=merge_twt_news.dropna()\n",
    "\n",
    "\n",
    "'''\n",
    "lets preprocess the text columns first, we will preprocess tweets and news seperately\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "twt_words=20000\n",
    "maxlen_twt=500\n",
    "\n",
    "tok_tweet = Tokenizer(num_words=twt_words)\n",
    "tok_tweet.fit_on_texts(merge_twt_news['content'])\n",
    "merge_twt_news['content']=tok_tweet.texts_to_sequences(merge_twt_news['content'])\n",
    "x_tweet = preprocessing.sequence.pad_sequences(merge_twt_news['content'], maxlen=500)\n",
    "\n",
    "\n",
    "#do the same fro the news\n",
    "\n",
    "news_words=30000\n",
    "maxlen_news=1500\n",
    "\n",
    "tok_news = Tokenizer(num_words=news_words)\n",
    "tok_news.fit_on_texts(merge_twt_news['title_x'])\n",
    "merge_twt_news['title_x']=tok_news.texts_to_sequences(merge_twt_news['title_x'])\n",
    "x_news = preprocessing.sequence.pad_sequences(merge_twt_news['title_x'], maxlen=maxlen_news)\n",
    "merge_twt_news=merge_twt_news.drop(['content', 'title_x'], axis=1)\n",
    "#col_dow=['t-6Dow','t-5Dow','t-4Dow','t-3Dow','t-2Dow','t-1Dow','t-6sp','t-5sp','t-4sp','t-3sp','t-2sp','t-1sp','t-6nas','t-5nas','t-4nas','t-3nas','t-2nas','t-1nas']\n",
    "\n",
    "\n",
    "col_sp=['t-6sp','t-5sp','t-4sp','t-3sp','t-2sp','t-1sp']\n",
    "col_nas=['t-6nas','t-5nas','t-4nas','t-3nas','t-2nas','t-1nas']\n",
    "col_dow=['t-6Dow','t-5Dow','t-4Dow','t-3Dow','t-2Dow','t-1Dow']\n",
    "#y=merge_twt_news['Up_Dow']\n",
    "\n",
    "\"\"\"\n",
    "Constructing our X dataset for each stock\n",
    "\n",
    "\"\"\"\n",
    "#Dow\n",
    "X_dowp=merge_twt_news[col_dow]\n",
    "X_dowp=np.hstack((x_tweet,x_news,X_dowp))\n",
    "\n",
    "#nas\n",
    "X_nasp=merge_twt_news[col_nas]\n",
    "X_nasp=np.hstack((x_tweet,x_news,X_nasp))\n",
    "\n",
    "#sp\n",
    "X_spp=merge_twt_news[col_sp]\n",
    "X_spp=np.hstack((x_tweet,x_news,X_spp))\n",
    "\n",
    "#X_dowp_train,X_dowp_test,y_dowp_train,y_dowp_test= train_test_split(X_dowp,merge_twt_news[['Up_Dow','Up_sp','Up_nas']],test_size=0.25,random_state=0) #['Up_Dow'] for class\n",
    "\n",
    "X_dowp_train,X_dowp_test,y_dowp_train,y_dowp_test= train_test_split(X_dowp,merge_twt_news[['Up_Dow']],test_size=0.01,random_state=42)\n",
    "X_nasp_train,X_nasp_test,y_nasp_train,y_nasp_test= train_test_split(X_nasp,merge_twt_news[['Up_nas']],test_size=0.01,random_state=42)\n",
    "X_spp_train,X_spp_test,y_spp_train,y_spp_test= train_test_split(X_spp,merge_twt_news[['Up_sp']],test_size=0.01,random_state=42)\n",
    "#X_dowp_test,X_dowp_val,y_dowp_test,y_dowp_val= train_test_split(X_dowp_test,y_dowp_test,test_size=0.5,random_state=0,stratify=y_dowp_test)\n",
    "\n",
    "\n",
    "\n",
    "word_index_twitter = tok_tweet.word_index\n",
    "word_index_news = tok_news.word_index\n",
    "\n",
    "\n",
    "\n",
    "#skf=StratifiedKFold(n_splits=10,random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "LETS START WORKING ON THE MODEL\n",
    "'''\n",
    "\n",
    "'''\n",
    "any model that we work on needs to beat the base model: we assume given the current economy\n",
    "that the stock market will be rising (dow in this case) so prediction will always be 1\n",
    "'''\n",
    "y_base=np.ones(len( X_dowp_train),)\n",
    "print(\"Base model for each stock\")\n",
    "print(\"Dow: \",np.mean(y_base==y_dowp_train['Up_Dow']))\n",
    "print(\"sp: \",np.mean(y_base==y_spp_train['Up_sp']))\n",
    "print(\"nas: \",np.mean(y_base==y_nasp_train['Up_nas'])) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start updating here please\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#2nd model no twitter but rnn\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy without twitter but rnn')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "#plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.title('Training and validation loss no twitt but rnn')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#3rd model rnn and twitter\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history3.history['accuracy']\n",
    "val_acc = history3.history['val_accuracy']\n",
    "loss = history3.history['loss']\n",
    "val_loss = history3.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy with twitter and rnn')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "#plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.title('Training and validation loss with twitt and rnn')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "now we need to start the regularization process as well as adding things to help\n",
    "solve the scarcity of data like pretrained embeddings \n",
    "also be careful we have a very big overfitting problem\n",
    "'''\n",
    "\n",
    "'''\n",
    "first we will try to handle lack of data by introducting a pre trained embedding vectors\n",
    "we will use the twitter GLOVE pretrained word vector\n",
    "lets prepare everything\n",
    "'''\n",
    "\n",
    "#unzip the twitter glove and setup the index\n",
    "import os\n",
    "\n",
    "glove_dir = 'C:\\\\Users\\\\marwe\\\\Desktop\\\\Glove'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.twitter.27B.100d.txt'),encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "#setup the vocab vector for the twitter dataset\n",
    "embedding_dim = 100\n",
    "embedding_matrix_tweet = np.zeros((twt_words, embedding_dim))\n",
    "for word, i in word_index_twitter.items():\n",
    "    if i < twt_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_tweet[i] = embedding_vector\n",
    "\n",
    "\n",
    "#setup the vocab vector for the news dataset\n",
    "embedding_dim = 100\n",
    "embedding_matrix_news = np.zeros((news_words, embedding_dim))\n",
    "for word, i in word_index_news.items():\n",
    "    if i < news_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_news[i] = embedding_vector\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all models constructed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "construct all models\n",
    "\"\"\"\n",
    "\n",
    "def model_0():\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words+1,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y=layers.Flatten()(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(80,name='f',recurrent_dropout=0.5,dropout=0.5,return_sequences=True)(input_hist)\n",
    "    z=layers.Flatten()(z)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined1 = layers.concatenate([y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(50, activation=\"tanh\",name='h')(combined1)\n",
    "    m=layers.Dropout(0.4)(m)\n",
    "    #dow = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    #sp = layers.Dense(1, activation=\"sigmoid\",name='j')(m)\n",
    "    nas= layers.Dense(1, activation=\"sigmoid\",name='k')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    #model = Model(inputs=[ y.input,z.input], outputs=[dow,sp,nas])\n",
    "    model = Model(inputs=[ y.input,z.input], outputs=nas)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    #model.compile(loss='mse', optimizer='rmsprop', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "lets introduce RNN for the news to see if we get better results \n",
    "\n",
    "'''\n",
    "def model_1():\n",
    "    #input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    \n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,return_sequences=False,name='e')(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(3,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),name='f')(input_hist)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), activation=\"relu\",name='h')(combined)\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "lets intorduce the twitter feed\n",
    "'''\n",
    "\n",
    "# define 3 sets of inputs\n",
    "def model_2():\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=64,input_length=500,name='a')(input_tweet)\n",
    "    x = layers.LSTM(32,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), return_sequences=False,name='b')(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=64,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),return_sequences=False,name='e')(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(3,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3),name='f')(input_hist)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(8,kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-3),\n",
    "        activity_regularizer=regularizers.l2(1e-3), activation=\"relu\",name='h')(combined)\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "after loading the glove embedding vectorizer, lets try our previous model and see what we obtain\n",
    "'''\n",
    "# define 3 sets of inputs\n",
    "def model_3():\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=embedding_dim,weights=[embedding_matrix_tweet],trainable=False,input_length=500,name='a')(input_tweet)\n",
    "    x = layers.LSTM(32,return_sequences=False,name='b')(x)\n",
    "    #x=layers.BatchNormalization()(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=embedding_dim,weights=[embedding_matrix_news],trainable=False,input_length=1500,name='c')(input_news)\n",
    "    y= layers.LSTM(32,return_sequences=False,name='e')(y)\n",
    "    y=layers.BatchNormalization()(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    z = layers.LSTM(6,name='f')(input_hist) #used to be 3\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(16, activation=\"relu\",name='h')(combined)#used to be 8\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    # our model will accept the inputs of the two branches and\n",
    "    # then output a single value\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    #model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "lets try some regulirazation techniques\n",
    "'''\n",
    "\n",
    "def model_4():\n",
    "# define 3 sets of inputs\n",
    "    input_tweet = Input(shape=(None,))\n",
    "    input_news = Input(shape=(None,))\n",
    "    input_hist=Input(shape=(6,1))\n",
    "    \n",
    "    \n",
    "    # the first branch operates on the first input\n",
    "    \n",
    "    x = layers.Embedding(input_dim=twt_words,output_dim=embedding_dim,weights=[embedding_matrix_tweet],trainable=False,input_length=500,name='a')(input_tweet)\n",
    "    #x = layers.Bidirectional(layers.LSTM(32,return_sequences=False,recurrent_dropout=0.33,dropout=0.33,name='b'))(x)\n",
    "    x=(layers.LSTM(30,return_sequences=True,recurrent_dropout=0.2,dropout=0.2,name='b'))(x)\n",
    "    #x=(layers.LSTM(100,return_sequences=True,recurrent_dropout=0.25,dropout=0.25,name='b'))(x)\n",
    "    #x=(layers.LSTM(50,return_sequences=True,recurrent_dropout=0.15,dropout=0.15,name='ba'))(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    #x=layers.BatchNormalization()(x)\n",
    "    #x=(layers.LSTM(40,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='t'))(x)\n",
    "    x = Model(inputs=input_tweet, outputs=x)\n",
    "    # the second branch opreates on the second input\n",
    "    y = layers.Embedding(input_dim=news_words,output_dim=embedding_dim,weights=[embedding_matrix_news],trainable=False,input_length=1500,name='c')(input_news)\n",
    "    #y= layers.Bidirectional(layers.LSTM(32,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='e'))(y)\n",
    "    y=(layers.LSTM(30,return_sequences=True,recurrent_dropout=0.2,dropout=0.2,name='e'))(y)\n",
    "    #y=(layers.LSTM(35,return_sequences=True,recurrent_dropout=0.15,dropout=0.15,name='ed'))(y)\n",
    "    y=layers.Flatten()(y)\n",
    "    #y=layers.BatchNormalization()(y)\n",
    "    #y=(layers.LSTM(40,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='ae'))(y)\n",
    "    y = Model(inputs=input_news, outputs=y)\n",
    "    \n",
    "    # the 3rd branch opreates on the 3rd input\n",
    "    \n",
    "    #z = layers.Bidirectional(layers.LSTM(6,name='f',recurrent_dropout=0.1,dropout=0.1))(input_hist)\n",
    "    #y= layers.Bidirectional(layers.LSTM(32,return_sequences=False,recurrent_dropout=0.2,dropout=0.2,name='e'))(y)\n",
    "    z = layers.LSTM(8,name='f',return_sequences=True)(input_hist)\n",
    "    z=layers.Flatten()(z)\n",
    "    z = Model(inputs=input_hist, outputs=z)\n",
    "    \n",
    "    \n",
    "    # combine the output of the two branches\n",
    "    combined = layers.concatenate([x.output,y.output,z.output],axis=-1,name='g')\n",
    "    \n",
    "    # apply a FC layer and then a regression prediction on the\n",
    "    # combined outputs\n",
    "    m = layers.Dense(10, activation=\"relu\",name='h')(combined)\n",
    "    m=layers.Dropout(0.2)(m)#used to be 8\n",
    "    m = layers.Dense(1, activation=\"sigmoid\",name='i')(m)\n",
    "    model = Model(inputs=[input_tweet, input_news,input_hist], outputs=m)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"all models constructed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nas training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 629 samples, validate on 158 samples\n",
      "Epoch 1/30\n",
      "629/629 [==============================] - 5s 7ms/step - loss: 0.9442 - accuracy: 0.5421 - val_loss: 0.7335 - val_accuracy: 0.5696\n",
      "Epoch 2/30\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.2974 - accuracy: 0.8442 - val_loss: 0.7088 - val_accuracy: 0.5570\n",
      "Epoch 3/30\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.0876 - accuracy: 0.9762 - val_loss: 0.7338 - val_accuracy: 0.4747\n",
      "Epoch 4/30\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.0259 - accuracy: 0.9984 - val_loss: 0.7311 - val_accuracy: 0.5506\n",
      "Epoch 5/30\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.5570\n",
      "Epoch 6/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.5570\n",
      "Epoch 7/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.5506\n",
      "Epoch 8/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.5506\n",
      "Epoch 9/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.7358 - val_accuracy: 0.5443\n",
      "Epoch 10/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.5443\n",
      "Epoch 11/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.5570\n",
      "Epoch 12/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.5506\n",
      "Epoch 13/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.5506\n",
      "Epoch 14/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.5506\n",
      "Epoch 15/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.5443\n",
      "Epoch 16/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.5443\n",
      "Epoch 17/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.5506\n",
      "Epoch 18/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.5506\n",
      "Epoch 19/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.5443\n",
      "Epoch 20/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.5443\n",
      "Epoch 21/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.5443\n",
      "Epoch 22/30\n",
      "629/629 [==============================] - 3s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.5443\n",
      "Epoch 23/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.5443\n",
      "Epoch 24/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 9.6730e-04 - accuracy: 1.0000 - val_loss: 0.7796 - val_accuracy: 0.5443\n",
      "Epoch 25/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 9.5491e-04 - accuracy: 1.0000 - val_loss: 0.7792 - val_accuracy: 0.5443\n",
      "Epoch 26/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.5443\n",
      "Epoch 27/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 9.1156e-04 - accuracy: 1.0000 - val_loss: 0.7837 - val_accuracy: 0.5443\n",
      "Epoch 28/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 7.9153e-04 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.5443\n",
      "Epoch 29/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 7.4619e-04 - accuracy: 1.0000 - val_loss: 0.7860 - val_accuracy: 0.5443\n",
      "Epoch 30/30\n",
      "629/629 [==============================] - 2s 4ms/step - loss: 8.1021e-04 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.5443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 629 samples, validate on 158 samples\n",
      "Epoch 1/30\n",
      "629/629 [==============================] - 24s 38ms/step - loss: 0.7680 - accuracy: 0.5135 - val_loss: 0.7612 - val_accuracy: 0.5759\n",
      "Epoch 2/30\n",
      "629/629 [==============================] - 26s 41ms/step - loss: 0.7549 - accuracy: 0.5962 - val_loss: 0.7534 - val_accuracy: 0.5759\n",
      "Epoch 3/30\n",
      "629/629 [==============================] - 26s 42ms/step - loss: 0.7364 - accuracy: 0.6025 - val_loss: 0.7522 - val_accuracy: 0.5696\n",
      "Epoch 4/30\n",
      "629/629 [==============================] - 26s 41ms/step - loss: 0.6728 - accuracy: 0.8871 - val_loss: 0.7635 - val_accuracy: 0.5127\n",
      "Epoch 5/30\n",
      "629/629 [==============================] - 27s 42ms/step - loss: 0.5651 - accuracy: 0.9809 - val_loss: 0.8355 - val_accuracy: 0.4430\n",
      "Epoch 6/30\n",
      "629/629 [==============================] - 27s 42ms/step - loss: 0.4373 - accuracy: 0.9984 - val_loss: 0.9049 - val_accuracy: 0.5127\n",
      "Epoch 7/30\n",
      "629/629 [==============================] - 27s 42ms/step - loss: 0.3974 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.5127\n",
      "Epoch 8/30\n",
      "629/629 [==============================] - 27s 42ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "629/629 [==============================] - 27s 42ms/step - loss: 0.3515 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.5063\n",
      "Epoch 10/30\n",
      "629/629 [==============================] - 28s 44ms/step - loss: 0.3333 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.5190\n",
      "Epoch 11/30\n",
      "629/629 [==============================] - 27s 43ms/step - loss: 0.3161 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.5127\n",
      "Epoch 12/30\n",
      "629/629 [==============================] - 27s 43ms/step - loss: 0.3003 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.5063\n",
      "Epoch 13/30\n",
      "629/629 [==============================] - 27s 44ms/step - loss: 0.2862 - accuracy: 1.0000 - val_loss: 1.0199 - val_accuracy: 0.5063\n",
      "Epoch 14/30\n",
      "629/629 [==============================] - 27s 43ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.5127\n",
      "Epoch 15/30\n",
      "629/629 [==============================] - 27s 43ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 1.0462 - val_accuracy: 0.5127\n",
      "Epoch 16/30\n",
      "629/629 [==============================] - 28s 45ms/step - loss: 0.2518 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.5190\n",
      "Epoch 17/30\n",
      "629/629 [==============================] - 29s 47ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.5253\n",
      "Epoch 18/30\n",
      "629/629 [==============================] - 29s 46ms/step - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.5316\n",
      "Epoch 19/30\n",
      "629/629 [==============================] - 29s 46ms/step - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.1031 - val_accuracy: 0.5190\n",
      "Epoch 20/30\n",
      "629/629 [==============================] - 29s 46ms/step - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.5190\n",
      "Epoch 21/30\n",
      "629/629 [==============================] - 29s 47ms/step - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.5190\n",
      "Epoch 22/30\n",
      "629/629 [==============================] - 29s 46ms/step - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.5063\n",
      "Epoch 23/30\n",
      "629/629 [==============================] - 30s 47ms/step - loss: 0.2009 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.5127\n",
      "Epoch 24/30\n",
      "629/629 [==============================] - 29s 46ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.5127\n",
      "Epoch 25/30\n",
      "629/629 [==============================] - 30s 47ms/step - loss: 0.1909 - accuracy: 1.0000 - val_loss: 1.1716 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "629/629 [==============================] - 29s 47ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 1.1996 - val_accuracy: 0.5127\n",
      "Epoch 27/30\n",
      "629/629 [==============================] - 29s 47ms/step - loss: 0.1821 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.5190\n",
      "Epoch 28/30\n",
      "629/629 [==============================] - 29s 47ms/step - loss: 0.1781 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "629/629 [==============================] - 30s 47ms/step - loss: 0.1743 - accuracy: 1.0000 - val_loss: 1.2413 - val_accuracy: 0.5063\n",
      "Epoch 30/30\n",
      "629/629 [==============================] - 31s 50ms/step - loss: 0.1707 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marwe\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 629 samples, validate on 158 samples\n",
      "Epoch 1/30\n",
      "629/629 [==============================] - 44s 69ms/step - loss: 2.2606 - accuracy: 0.5946 - val_loss: 2.0395 - val_accuracy: 0.5759\n",
      "Epoch 2/30\n",
      "629/629 [==============================] - 39s 62ms/step - loss: 1.8548 - accuracy: 0.5962 - val_loss: 1.6882 - val_accuracy: 0.5759\n",
      "Epoch 3/30\n",
      "629/629 [==============================] - 39s 62ms/step - loss: 1.5164 - accuracy: 0.5962 - val_loss: 1.9627 - val_accuracy: 0.5759\n",
      "Epoch 4/30\n",
      "629/629 [==============================] - 39s 62ms/step - loss: 1.2725 - accuracy: 0.6343 - val_loss: 1.3017 - val_accuracy: 0.5633\n",
      "Epoch 5/30\n",
      "629/629 [==============================] - 39s 63ms/step - loss: 1.0227 - accuracy: 0.9046 - val_loss: 1.1900 - val_accuracy: 0.5570\n",
      "Epoch 6/30\n",
      "629/629 [==============================] - 39s 62ms/step - loss: 0.8535 - accuracy: 0.9682 - val_loss: 1.1402 - val_accuracy: 0.5696\n",
      "Epoch 7/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.7246 - accuracy: 0.9984 - val_loss: 1.0714 - val_accuracy: 0.5316\n",
      "Epoch 8/30\n",
      "629/629 [==============================] - 43s 69ms/step - loss: 0.6287 - accuracy: 0.9984 - val_loss: 1.0526 - val_accuracy: 0.5127\n",
      "Epoch 9/30\n",
      "629/629 [==============================] - 42s 68ms/step - loss: 0.5589 - accuracy: 0.9968 - val_loss: 1.0450 - val_accuracy: 0.4557\n",
      "Epoch 10/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.5085 - accuracy: 1.0000 - val_loss: 1.0370 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.4701 - accuracy: 0.9984 - val_loss: 1.0324 - val_accuracy: 0.5127\n",
      "Epoch 12/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.4413 - accuracy: 1.0000 - val_loss: 1.0402 - val_accuracy: 0.5253\n",
      "Epoch 13/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.4175 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.5253\n",
      "Epoch 14/30\n",
      "629/629 [==============================] - 44s 70ms/step - loss: 0.3990 - accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 0.5316\n",
      "Epoch 15/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.3834 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.5380\n",
      "Epoch 16/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 1.0197 - val_accuracy: 0.5506\n",
      "Epoch 17/30\n",
      "629/629 [==============================] - 43s 69ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.5506\n",
      "Epoch 18/30\n",
      "629/629 [==============================] - 44s 71ms/step - loss: 0.3454 - accuracy: 1.0000 - val_loss: 1.0193 - val_accuracy: 0.5127\n",
      "Epoch 19/30\n",
      "629/629 [==============================] - 43s 69ms/step - loss: 0.3345 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.5443\n",
      "Epoch 20/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.3246 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.5633\n",
      "Epoch 21/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.3172 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.5316\n",
      "Epoch 22/30\n",
      "629/629 [==============================] - 44s 71ms/step - loss: 0.3257 - accuracy: 0.9936 - val_loss: 1.2193 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.3283 - accuracy: 0.9968 - val_loss: 1.0327 - val_accuracy: 0.4810\n",
      "Epoch 24/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.3065 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.5127\n",
      "Epoch 25/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.2939 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.5063\n",
      "Epoch 26/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.5380\n",
      "Epoch 27/30\n",
      "629/629 [==============================] - 44s 69ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.5316\n",
      "Epoch 28/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.2712 - accuracy: 1.0000 - val_loss: 1.0260 - val_accuracy: 0.5316\n",
      "Epoch 29/30\n",
      "629/629 [==============================] - 42s 67ms/step - loss: 0.2655 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.5316\n",
      "Epoch 30/30\n",
      "629/629 [==============================] - 43s 68ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.5063\n",
      "Train on 629 samples, validate on 158 samples\n",
      "Epoch 1/30\n",
      "629/629 [==============================] - 44s 70ms/step - loss: 0.7570 - accuracy: 0.4992 - val_loss: 0.6997 - val_accuracy: 0.5759\n",
      "Epoch 2/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.6392 - accuracy: 0.6280 - val_loss: 0.6976 - val_accuracy: 0.5759\n",
      "Epoch 3/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.5824 - accuracy: 0.6963 - val_loss: 0.6923 - val_accuracy: 0.5759\n",
      "Epoch 4/30\n",
      "629/629 [==============================] - 40s 63ms/step - loss: 0.5420 - accuracy: 0.7504 - val_loss: 0.7045 - val_accuracy: 0.5759\n",
      "Epoch 5/30\n",
      "629/629 [==============================] - 39s 61ms/step - loss: 0.5028 - accuracy: 0.7742 - val_loss: 0.7108 - val_accuracy: 0.5759\n",
      "Epoch 6/30\n",
      "629/629 [==============================] - 34s 53ms/step - loss: 0.4611 - accuracy: 0.8060 - val_loss: 0.7263 - val_accuracy: 0.5759\n",
      "Epoch 7/30\n",
      "629/629 [==============================] - 34s 53ms/step - loss: 0.4173 - accuracy: 0.8521 - val_loss: 0.7257 - val_accuracy: 0.5696\n",
      "Epoch 8/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.3742 - accuracy: 0.8776 - val_loss: 0.7415 - val_accuracy: 0.5443\n",
      "Epoch 9/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.3264 - accuracy: 0.8951 - val_loss: 0.7633 - val_accuracy: 0.5316\n",
      "Epoch 10/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.2764 - accuracy: 0.9332 - val_loss: 0.7728 - val_accuracy: 0.5506\n",
      "Epoch 11/30\n",
      "629/629 [==============================] - 34s 54ms/step - loss: 0.2542 - accuracy: 0.9412 - val_loss: 0.8010 - val_accuracy: 0.5443\n",
      "Epoch 12/30\n",
      "629/629 [==============================] - 34s 54ms/step - loss: 0.2042 - accuracy: 0.9587 - val_loss: 0.8533 - val_accuracy: 0.5063\n",
      "Epoch 13/30\n",
      "629/629 [==============================] - 34s 53ms/step - loss: 0.1670 - accuracy: 0.9666 - val_loss: 0.9312 - val_accuracy: 0.5063\n",
      "Epoch 14/30\n",
      "629/629 [==============================] - 34s 54ms/step - loss: 0.1228 - accuracy: 0.9873 - val_loss: 1.1041 - val_accuracy: 0.4937\n",
      "Epoch 15/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.1107 - accuracy: 0.9809 - val_loss: 1.0395 - val_accuracy: 0.5127\n",
      "Epoch 16/30\n",
      "629/629 [==============================] - 34s 54ms/step - loss: 0.0775 - accuracy: 0.9936 - val_loss: 1.1972 - val_accuracy: 0.4810\n",
      "Epoch 17/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0598 - accuracy: 0.9968 - val_loss: 1.3950 - val_accuracy: 0.4937\n",
      "Epoch 18/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.4873\n",
      "Epoch 19/30\n",
      "629/629 [==============================] - 34s 53ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.4873\n",
      "Epoch 20/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.4747\n",
      "Epoch 21/30\n",
      "629/629 [==============================] - 34s 53ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.7782 - val_accuracy: 0.4684\n",
      "Epoch 22/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0172 - accuracy: 0.9984 - val_loss: 1.8878 - val_accuracy: 0.4937\n",
      "Epoch 23/30\n",
      "629/629 [==============================] - 34s 54ms/step - loss: 0.0215 - accuracy: 0.9984 - val_loss: 1.9164 - val_accuracy: 0.5063\n",
      "Epoch 24/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0245 - accuracy: 0.9968 - val_loss: 2.0388 - val_accuracy: 0.4177\n",
      "Epoch 25/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 2.3636 - val_accuracy: 0.5127\n",
      "Epoch 26/30\n",
      "629/629 [==============================] - 33s 52ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.1091 - val_accuracy: 0.4494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "629/629 [==============================] - 33s 52ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 2.0437 - val_accuracy: 0.4810\n",
      "Epoch 28/30\n",
      "629/629 [==============================] - 33s 52ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.1713 - val_accuracy: 0.4494\n",
      "Epoch 29/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.2146 - val_accuracy: 0.4304\n",
      "Epoch 30/30\n",
      "629/629 [==============================] - 33s 53ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2548 - val_accuracy: 0.4494\n",
      "Train on 629 samples, validate on 158 samples\n",
      "Epoch 1/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.6936 - accuracy: 0.5739 - val_loss: 0.6847 - val_accuracy: 0.5759\n",
      "Epoch 2/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.6794 - accuracy: 0.5978 - val_loss: 0.6829 - val_accuracy: 0.5759\n",
      "Epoch 3/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.6729 - accuracy: 0.5946 - val_loss: 0.6872 - val_accuracy: 0.5696\n",
      "Epoch 4/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.6691 - accuracy: 0.5962 - val_loss: 0.6810 - val_accuracy: 0.5759\n",
      "Epoch 5/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.6405 - accuracy: 0.5978 - val_loss: 0.6801 - val_accuracy: 0.5759\n",
      "Epoch 6/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.5994 - accuracy: 0.5994 - val_loss: 0.7105 - val_accuracy: 0.5759\n",
      "Epoch 7/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.5457 - accuracy: 0.6025 - val_loss: 0.6865 - val_accuracy: 0.5759\n",
      "Epoch 8/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.5170 - accuracy: 0.5978 - val_loss: 0.7563 - val_accuracy: 0.5759\n",
      "Epoch 9/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.4547 - accuracy: 0.7409 - val_loss: 0.7464 - val_accuracy: 0.6013\n",
      "Epoch 10/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.4107 - accuracy: 0.8331 - val_loss: 0.7806 - val_accuracy: 0.6076\n",
      "Epoch 11/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.3726 - accuracy: 0.8760 - val_loss: 0.8818 - val_accuracy: 0.6076\n",
      "Epoch 12/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.3517 - accuracy: 0.8855 - val_loss: 1.1848 - val_accuracy: 0.5823\n",
      "Epoch 13/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.3271 - accuracy: 0.8824 - val_loss: 0.8985 - val_accuracy: 0.5886\n",
      "Epoch 14/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.2800 - accuracy: 0.9205 - val_loss: 0.8936 - val_accuracy: 0.5443\n",
      "Epoch 15/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.2540 - accuracy: 0.9030 - val_loss: 1.0567 - val_accuracy: 0.5570\n",
      "Epoch 16/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.1542 - accuracy: 0.9475 - val_loss: 1.1338 - val_accuracy: 0.5696\n",
      "Epoch 17/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.1726 - accuracy: 0.9253 - val_loss: 1.0907 - val_accuracy: 0.6076\n",
      "Epoch 18/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.1383 - accuracy: 0.9539 - val_loss: 1.2264 - val_accuracy: 0.6203\n",
      "Epoch 19/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.1597 - accuracy: 0.9205 - val_loss: 1.1551 - val_accuracy: 0.5886\n",
      "Epoch 20/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.1335 - accuracy: 0.9396 - val_loss: 1.3461 - val_accuracy: 0.5823\n",
      "Epoch 21/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.0904 - accuracy: 0.9555 - val_loss: 1.3682 - val_accuracy: 0.5886\n",
      "Epoch 22/30\n",
      "629/629 [==============================] - 37s 59ms/step - loss: 0.1103 - accuracy: 0.9539 - val_loss: 1.3321 - val_accuracy: 0.5823\n",
      "Epoch 23/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.0982 - accuracy: 0.9603 - val_loss: 1.7272 - val_accuracy: 0.6266\n",
      "Epoch 24/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.1117 - accuracy: 0.9475 - val_loss: 1.2040 - val_accuracy: 0.5696\n",
      "Epoch 25/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.0975 - accuracy: 0.9571 - val_loss: 1.5871 - val_accuracy: 0.5696\n",
      "Epoch 26/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.0881 - accuracy: 0.9650 - val_loss: 1.6181 - val_accuracy: 0.5506\n",
      "Epoch 27/30\n",
      "629/629 [==============================] - 37s 58ms/step - loss: 0.0995 - accuracy: 0.9571 - val_loss: 1.3121 - val_accuracy: 0.5759\n",
      "Epoch 28/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.0716 - accuracy: 0.9618 - val_loss: 1.7448 - val_accuracy: 0.5823\n",
      "Epoch 29/30\n",
      "629/629 [==============================] - 36s 57ms/step - loss: 0.0927 - accuracy: 0.9555 - val_loss: 1.4987 - val_accuracy: 0.5949\n",
      "Epoch 30/30\n",
      "629/629 [==============================] - 36s 58ms/step - loss: 0.0831 - accuracy: 0.9650 - val_loss: 1.6548 - val_accuracy: 0.5696\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "\n",
    "# Do some code, e.g. train and save model\n",
    "\n",
    "\n",
    "print(\"Nas training\")\n",
    "\n",
    "history_nas=model_0().fit([X_nasp_train[:,500:2000],np.reshape(X_nasp_train[:,2000:],(len(X_nasp_train),6,1))], y_nasp_train['Up_nas'], epochs=30, validation_split =0.20,verbose=1)\n",
    "history_nas_1=model_1().fit([X_nasp_train[:,500:2000],np.reshape(X_nasp_train[:,2000:],(len(X_nasp_train),6,1))], y_nasp_train['Up_nas'], epochs=30, validation_split =0.20,verbose=1)\n",
    "history_nas_2=model_2().fit([X_nasp_train[:,:500],X_nasp_train[:,500:2000],np.reshape(X_nasp_train[:,2000:],(len( X_dowp_train),6,1))], y_nasp_train, epochs=30, batch_size=28, validation_split=0.20,verbose=1)\n",
    "history_nas_3=model_3().fit([X_nasp_train[:,:500],X_nasp_train[:,500:2000],np.reshape(X_nasp_train[:,2000:],(len( X_dowp_train),6,1))], y_nasp_train, epochs=30, batch_size=28, validation_split=0.20,verbose=1)\n",
    "history_nas_4=model_4().fit([X_nasp_train[:,:500],X_nasp_train[:,500:2000],np.reshape(X_nasp_train[:,2000:],(len( X_dowp_train),6,1))], y_nasp_train, epochs=30, batch_size=28, validation_split=0.20,verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nasdaq comparison\n",
    "\n",
    "acc_nas = history_nas.history['accuracy']\n",
    "val_acc_nas = history_nas.history['val_accuracy']\n",
    "acc_nas_1 = history_nas_1.history['accuracy']\n",
    "val_acc_nas_1 = history_nas_1.history['val_accuracy']\n",
    "acc_nas_2 = history_nas_2.history['accuracy']\n",
    "val_acc_nas_2 = history_nas_2.history['val_accuracy']\n",
    "acc_nas_3 = history_nas_3.history['accuracy']\n",
    "val_acc_nas_3 = history_nas_3.history['val_accuracy']\n",
    "\n",
    "acc_nas_4 = history_nas_4.history['accuracy']\n",
    "val_acc_nas_4 = history_nas_4.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_nas_4) + 1)\n",
    "\n",
    "plt.plot(epochs, val_acc_nas, label='Val nas lvl0')\n",
    "plt.plot(epochs, val_acc_nas_1, label='Val nas lvl1')\n",
    "plt.plot(epochs, val_acc_nas_2, label='Val nas lvl2')\n",
    "plt.plot(epochs, val_acc_nas_3, label='Val nas lvl3')\n",
    "plt.plot(epochs, val_acc_nas_4, label='Val nas lvl4')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('validation comparison for nasdaq')\n",
    "plt.legend()\n",
    "#plt.figure()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
